{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e0dbf53625604542b59b63b1957539df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94f69c0e9f014c96b886161c0c24d36c",
              "IPY_MODEL_cd5ef57910d74dc8ba7e314f0392e9ee",
              "IPY_MODEL_15711429ac6d41818d3d3f7de37b9f0b"
            ],
            "layout": "IPY_MODEL_04c90029e657496b9048f2b59287a23e"
          }
        },
        "94f69c0e9f014c96b886161c0c24d36c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ab241acc1dd4ba7b20b70319e596c35",
            "placeholder": "​",
            "style": "IPY_MODEL_3ac2e17d9fa548bba67bf5a7c8739f07",
            "value": "Downloading data: 100%"
          }
        },
        "cd5ef57910d74dc8ba7e314f0392e9ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0517566c6df43b1ab882a3c96c7a6c1",
            "max": 6372817,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2fa5bd49c4846af938c86233961a5a0",
            "value": 6372817
          }
        },
        "15711429ac6d41818d3d3f7de37b9f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4e029628caa4a8892da694d18d1992d",
            "placeholder": "​",
            "style": "IPY_MODEL_603c8d0f7bfb4bf2b0c96df4315c9563",
            "value": " 6.37M/6.37M [00:02&lt;00:00, 5.98MB/s]"
          }
        },
        "04c90029e657496b9048f2b59287a23e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab241acc1dd4ba7b20b70319e596c35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ac2e17d9fa548bba67bf5a7c8739f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0517566c6df43b1ab882a3c96c7a6c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2fa5bd49c4846af938c86233961a5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4e029628caa4a8892da694d18d1992d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "603c8d0f7bfb4bf2b0c96df4315c9563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03b0b77c79c3434bb9b8e8f5ee83bacc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e964adeed9194b2ea7c85069b0ccd9bf",
              "IPY_MODEL_9fe737afcfab45f7a8545119a92d24d6",
              "IPY_MODEL_6ae2be4939094674804fd511a15bbb71"
            ],
            "layout": "IPY_MODEL_f2ce504e2a614bc5a30a3e2c3b12ebc3"
          }
        },
        "e964adeed9194b2ea7c85069b0ccd9bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61f6fc8d215648cd97d8aa629a8d17bb",
            "placeholder": "​",
            "style": "IPY_MODEL_0a8dfd2ae49e4d1ab5760a436251a458",
            "value": "Downloading data: 100%"
          }
        },
        "9fe737afcfab45f7a8545119a92d24d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e64f22ee29bc47f69b5f308297caaacd",
            "max": 789539,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_894e16942a6241308c358e68ae3e6e30",
            "value": 789539
          }
        },
        "6ae2be4939094674804fd511a15bbb71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cfc99cc140b4d9aa7064dee3ec5c8b9",
            "placeholder": "​",
            "style": "IPY_MODEL_ca8a30dac94e4e10b31741513d713b99",
            "value": " 790k/790k [00:00&lt;00:00, 1.17MB/s]"
          }
        },
        "f2ce504e2a614bc5a30a3e2c3b12ebc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61f6fc8d215648cd97d8aa629a8d17bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a8dfd2ae49e4d1ab5760a436251a458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e64f22ee29bc47f69b5f308297caaacd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "894e16942a6241308c358e68ae3e6e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cfc99cc140b4d9aa7064dee3ec5c8b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca8a30dac94e4e10b31741513d713b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2003aefbaf96452c912b4f9d0d16af5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22c3ec6f47b84913adf50f2ccf9acb38",
              "IPY_MODEL_cef80e7c3f76434a82fc1a5f12959e52",
              "IPY_MODEL_a092019d38b541228f53992f9014d670"
            ],
            "layout": "IPY_MODEL_1013ee863177422488ff549d5c15b89e"
          }
        },
        "22c3ec6f47b84913adf50f2ccf9acb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_055fcd5ff04347778a9245350a8f7482",
            "placeholder": "​",
            "style": "IPY_MODEL_a2051a99d4744ba1ab05763504d61053",
            "value": "Generating train split: 100%"
          }
        },
        "cef80e7c3f76434a82fc1a5f12959e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71f49407bb9f4f959f5dfa8328ee71d7",
            "max": 8544,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a38b2cf930fd4c29a6f2622015e10fb9",
            "value": 8544
          }
        },
        "a092019d38b541228f53992f9014d670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8aa0eb220bf4e139d954d83131e534e",
            "placeholder": "​",
            "style": "IPY_MODEL_1ea208ee763e4c15bbe1636f8a870d63",
            "value": " 8544/8544 [00:01&lt;00:00, 9582.23 examples/s]"
          }
        },
        "1013ee863177422488ff549d5c15b89e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "055fcd5ff04347778a9245350a8f7482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2051a99d4744ba1ab05763504d61053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71f49407bb9f4f959f5dfa8328ee71d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a38b2cf930fd4c29a6f2622015e10fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8aa0eb220bf4e139d954d83131e534e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ea208ee763e4c15bbe1636f8a870d63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "618c931591cd49f693f6968d40a620df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2f5cc910c3d49c7aa39fc710672ac4a",
              "IPY_MODEL_eb25ab79704d464e9f108dd5a72d50c8",
              "IPY_MODEL_cb67f1c69e004c1ab14fa1bffcf8149a"
            ],
            "layout": "IPY_MODEL_b55705984302438d86f8fa9341af333b"
          }
        },
        "d2f5cc910c3d49c7aa39fc710672ac4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9793ba96338341b19cb414e754f014fe",
            "placeholder": "​",
            "style": "IPY_MODEL_3f63b1977d1048d4bfdb562370935130",
            "value": "Generating validation split: 100%"
          }
        },
        "eb25ab79704d464e9f108dd5a72d50c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aaf35371dc54a11bc25a370e413afb5",
            "max": 1101,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c88e9008005e4873b717fe3e5e75b3f1",
            "value": 1101
          }
        },
        "cb67f1c69e004c1ab14fa1bffcf8149a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d822280e84c434899ce559e33e35f3b",
            "placeholder": "​",
            "style": "IPY_MODEL_9e94ab67af6146bfa570417b4b69bfb4",
            "value": " 1101/1101 [00:00&lt;00:00,  1.22 examples/s]"
          }
        },
        "b55705984302438d86f8fa9341af333b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9793ba96338341b19cb414e754f014fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f63b1977d1048d4bfdb562370935130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9aaf35371dc54a11bc25a370e413afb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c88e9008005e4873b717fe3e5e75b3f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d822280e84c434899ce559e33e35f3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e94ab67af6146bfa570417b4b69bfb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c21faf4ee494142923b539699907d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a61fd1cd7204de5901120d2838ad909",
              "IPY_MODEL_f5ece8ac5df345bcb7e3ae3138c83015",
              "IPY_MODEL_438c643d66a24b41b328243aff2f62e3"
            ],
            "layout": "IPY_MODEL_97c5e614789146efbee7631d1232c949"
          }
        },
        "0a61fd1cd7204de5901120d2838ad909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66fab172af8643aeb03b7924a45be51a",
            "placeholder": "​",
            "style": "IPY_MODEL_fa56fd7783464f4bbe6b4de67b778d93",
            "value": "Generating test split: 100%"
          }
        },
        "f5ece8ac5df345bcb7e3ae3138c83015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bb104889961463abd1935e8572a5071",
            "max": 2210,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9cabf4de7b242fbad49e0e1660ffca6",
            "value": 2210
          }
        },
        "438c643d66a24b41b328243aff2f62e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1558749faf74134a27a7a0ff5f85ed5",
            "placeholder": "​",
            "style": "IPY_MODEL_0780afb80bb7485eb1d7e1ed36ca9f8a",
            "value": " 2210/2210 [00:00&lt;00:00, 3148.40 examples/s]"
          }
        },
        "97c5e614789146efbee7631d1232c949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66fab172af8643aeb03b7924a45be51a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa56fd7783464f4bbe6b4de67b778d93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bb104889961463abd1935e8572a5071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9cabf4de7b242fbad49e0e1660ffca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1558749faf74134a27a7a0ff5f85ed5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0780afb80bb7485eb1d7e1ed36ca9f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95b079e00e2f4d0280332124d423f154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_adbc5bbeb85641f38a0a1df31e90a064",
              "IPY_MODEL_7d6352ced01d493083ad6258b76b7941",
              "IPY_MODEL_a13601f49b3b4a7ebc0840621a668976"
            ],
            "layout": "IPY_MODEL_29b3eecb451343a3b644e90606482e9b"
          }
        },
        "adbc5bbeb85641f38a0a1df31e90a064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d68a2275aa241889a8e8183d8d242b0",
            "placeholder": "​",
            "style": "IPY_MODEL_23d61c515a534845909ee05a249be309",
            "value": "Amazon-Reviews-2023.py: 100%"
          }
        },
        "7d6352ced01d493083ad6258b76b7941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1198bdd69d2b42d8a4c21290ea948732",
            "max": 39620,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3cce705f0b7e420bb3d26c134550b1e0",
            "value": 39620
          }
        },
        "a13601f49b3b4a7ebc0840621a668976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4214dc1c0974ecaa2bad02222c0092b",
            "placeholder": "​",
            "style": "IPY_MODEL_3bd681ba074446dc9a25d48699986cb6",
            "value": " 39.6k/39.6k [00:00&lt;00:00, 3.00MB/s]"
          }
        },
        "29b3eecb451343a3b644e90606482e9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d68a2275aa241889a8e8183d8d242b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23d61c515a534845909ee05a249be309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1198bdd69d2b42d8a4c21290ea948732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cce705f0b7e420bb3d26c134550b1e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4214dc1c0974ecaa2bad02222c0092b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bd681ba074446dc9a25d48699986cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d51914f5006047a09bbe3907256c73d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_71f92b756aa544f6819453d7f4a87275",
              "IPY_MODEL_3a4c30222cd1441b914128be88680921",
              "IPY_MODEL_1d34bbda59b14a6cbe9892388f9bbe58"
            ],
            "layout": "IPY_MODEL_91e48920dea6485ab43ebbf177181074"
          }
        },
        "71f92b756aa544f6819453d7f4a87275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_503b86ce45ce4d04a4f25e597b623e61",
            "placeholder": "​",
            "style": "IPY_MODEL_dfe8544855844c03af54ce9d19e43bdc",
            "value": "README.md: 100%"
          }
        },
        "3a4c30222cd1441b914128be88680921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b592f895cbf94cc59b0f3f848f65a3c2",
            "max": 19737,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58c75ed299344e4eae358658b30cf4a1",
            "value": 19737
          }
        },
        "1d34bbda59b14a6cbe9892388f9bbe58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_580b7b229901427fb5d3186bc40fab76",
            "placeholder": "​",
            "style": "IPY_MODEL_e6e18ee3788b42c5886638f203ba5a81",
            "value": " 19.7k/19.7k [00:00&lt;00:00, 1.64MB/s]"
          }
        },
        "91e48920dea6485ab43ebbf177181074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "503b86ce45ce4d04a4f25e597b623e61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfe8544855844c03af54ce9d19e43bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b592f895cbf94cc59b0f3f848f65a3c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c75ed299344e4eae358658b30cf4a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "580b7b229901427fb5d3186bc40fab76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6e18ee3788b42c5886638f203ba5a81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "deac4c1bf0984e2bb0f0f733c7eb481a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51f7e2727166411d8b97e44de706d4a5",
              "IPY_MODEL_8b091cfb9e9b42718ed52bf2b76cf572",
              "IPY_MODEL_9e2787fd87034043b85e4703dcd2523e"
            ],
            "layout": "IPY_MODEL_95065fd8fd5744f3a4167259ee8281af"
          }
        },
        "51f7e2727166411d8b97e44de706d4a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8342bd08e0824656b9dac9d92cc46882",
            "placeholder": "​",
            "style": "IPY_MODEL_eaed1fc1b283415ba2d28d58666a29a4",
            "value": "All_Beauty.jsonl: 100%"
          }
        },
        "8b091cfb9e9b42718ed52bf2b76cf572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74b16dda9557440695257c8843916452",
            "max": 326611506,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf84583ddea04080a8ded280eff084f0",
            "value": 326611506
          }
        },
        "9e2787fd87034043b85e4703dcd2523e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0b1cc050df045f3bc886f5a1454e027",
            "placeholder": "​",
            "style": "IPY_MODEL_361f9efed80945c08f441898320aa416",
            "value": " 327M/327M [00:01&lt;00:00, 259MB/s]"
          }
        },
        "95065fd8fd5744f3a4167259ee8281af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8342bd08e0824656b9dac9d92cc46882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaed1fc1b283415ba2d28d58666a29a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74b16dda9557440695257c8843916452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf84583ddea04080a8ded280eff084f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0b1cc050df045f3bc886f5a1454e027": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "361f9efed80945c08f441898320aa416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0eaaf15400874f7a880d658c0e1d75b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8aed96563b754f3ebed7ea22c257c16c",
              "IPY_MODEL_50b5af3114204cc896a10770841238df",
              "IPY_MODEL_16b62f9463d5444db52315c8992647e9"
            ],
            "layout": "IPY_MODEL_153c490e2ac2449ab207f17f19a1c39b"
          }
        },
        "8aed96563b754f3ebed7ea22c257c16c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68e76bd8a02d42de84b4adaa7855a46e",
            "placeholder": "​",
            "style": "IPY_MODEL_88d9983be3794bfa9560bfb1933cd73b",
            "value": "Generating full split: "
          }
        },
        "50b5af3114204cc896a10770841238df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9002c011ba74d8db5a5b2dc532e5564",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cca0e076ccba43fe99486eb6577bea16",
            "value": 1
          }
        },
        "16b62f9463d5444db52315c8992647e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2343e04b1464844a251853897253055",
            "placeholder": "​",
            "style": "IPY_MODEL_036b2df7d5334e6a8e26a545be1f507e",
            "value": " 701528/0 [00:13&lt;00:00, 55115.07 examples/s]"
          }
        },
        "153c490e2ac2449ab207f17f19a1c39b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68e76bd8a02d42de84b4adaa7855a46e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d9983be3794bfa9560bfb1933cd73b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9002c011ba74d8db5a5b2dc532e5564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "cca0e076ccba43fe99486eb6577bea16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2343e04b1464844a251853897253055": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "036b2df7d5334e6a8e26a545be1f507e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "YurdG8Q-2zDh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C-LSTM with the embedding layer with the pre-trained glove embeddings\n",
        "class CLSTMBinaryClassifierIMDB(tf.keras.Model):\n",
        "    def __init__(self, config, embedding_matrix):\n",
        "        super(CLSTMBinaryClassifierIMDB, self).__init__()\n",
        "        self.max_length = config.max_length\n",
        "        self.num_classes = config.num_classes\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.embedding_size = config.embedding_size\n",
        "        self.filter_sizes = list(map(int, config.filter_sizes.split(\",\")))\n",
        "        self.num_filters = config.num_filters\n",
        "        self.num_layers = config.num_layers\n",
        "        self.hidden_size = len(self.filter_sizes) * self.num_filters\n",
        "        self.l2_reg_lambda = config.l2_reg_lambda\n",
        "\n",
        "        # embedding layer initialized with glove embeddings\n",
        "        self.embedding = layers.Embedding(input_dim=self.vocab_size,\n",
        "                                          output_dim=self.embedding_size,\n",
        "                                          input_length=self.max_length,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          trainable=True)\n",
        "\n",
        "        # conv layers for different filter sizes\n",
        "        self.conv_layers = [\n",
        "            layers.Conv2D(filters=self.num_filters,\n",
        "                          kernel_size=(filter_size, self.embedding_size),\n",
        "                          activation='relu', padding='valid')\n",
        "            for filter_size in self.filter_sizes\n",
        "        ]\n",
        "\n",
        "        # lstm layer\n",
        "        self.lstm = layers.LSTM(self.hidden_size, return_sequences=False)\n",
        "\n",
        "        self.dropout = layers.Dropout(rate=config.keep_prob)\n",
        "\n",
        "        self.fc = layers.Dense(self.num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(self.l2_reg_lambda))\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        input_x = inputs\n",
        "        x = self.embedding(input_x)  # [batch_size, max_length, embedding_size]\n",
        "        x = tf.expand_dims(x, -1)    # [batch_size, max_length, embedding_size, 1]\n",
        "\n",
        "        conv_outputs = []\n",
        "        for conv_layer in self.conv_layers:\n",
        "            conv = conv_layer(x)\n",
        "            conv = tf.squeeze(conv, 2)  # squeezing out the 'channels' dimension\n",
        "            conv_outputs.append(conv)\n",
        "\n",
        "        # the minimum sequence length across all convolution outputs\n",
        "        min_length = min([conv.shape[1] for conv in conv_outputs])\n",
        "\n",
        "        # trimmikng all convolution outputs to the same sequence length\n",
        "        conv_outputs = [conv[:, :min_length, :] for conv in conv_outputs]\n",
        "\n",
        "        if len(conv_outputs) > 1:\n",
        "            rnn_inputs = tf.concat(conv_outputs, -1)  # concat along the last dimension\n",
        "        else:\n",
        "            rnn_inputs = conv_outputs[0]\n",
        "\n",
        "        # feed it to the LSTM\n",
        "        rnn_outputs = self.lstm(rnn_inputs)\n",
        "\n",
        "        rnn_outputs = self.dropout(rnn_outputs, training=training)\n",
        "\n",
        "        # final output layer\n",
        "        logits = self.fc(rnn_outputs)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "BhfzmgTW202Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "MAX_LEN = 500  # max length of sequences (padded or truncated)\n",
        "VOCAB_SIZE = 5000  # the vocabulary\n",
        "EMBEDDING_DIM = 300  # glove embedding dimensions"
      ],
      "metadata": {
        "id": "LUhfXPkP2-yk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BINARY C-LSTM ON IMDB"
      ],
      "metadata": {
        "id": "5Icq_eKV3PkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=VOCAB_SIZE)\n",
        "\n",
        "# padding the sequences to ensure uniform input size\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=MAX_LEN)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=MAX_LEN)\n",
        "\n",
        "\n",
        "def load_glove_embeddings(glove_file_path, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding_vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = embedding_vector\n",
        "    return embeddings_index\n",
        "\n",
        "def create_embedding_matrix(word_index, glove_embeddings, vocab_size, embedding_dim):\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i < vocab_size:  # Only consider the top 'vocab_size' words\n",
        "            embedding_vector = glove_embeddings.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                # Words not found in the embedding index will be all zeros.\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "glove_file_path = '/content/drive/MyDrive/glove/glove.6B.300d.txt'\n",
        "glove_embeddings = load_glove_embeddings(glove_file_path, EMBEDDING_DIM)\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "embedding_matrix = create_embedding_matrix(word_index, glove_embeddings, VOCAB_SIZE, EMBEDDING_DIM)\n",
        "\n",
        "class Config:\n",
        "    max_length = MAX_LEN\n",
        "    num_classes = 2  # imdb is binary classification (positive/negative)\n",
        "    vocab_size = VOCAB_SIZE\n",
        "    embedding_size = EMBEDDING_DIM  # glove embedding dimension\n",
        "    filter_sizes = \"3,4,5\"\n",
        "    num_filters = 64\n",
        "    num_layers = 1\n",
        "    l2_reg_lambda = 0.1\n",
        "    keep_prob = 0.5\n",
        "\n",
        "config = Config()\n",
        "model = CLSTMBinaryClassifierIMDB(config, embedding_matrix)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTkVRkDh3CPa",
        "outputId": "7ca29bce-ea63-433a-b73d-ee0a16ed6ff4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.5652 - loss: 0.8189 - val_accuracy: 0.6956 - val_loss: 0.6310\n",
            "Epoch 2/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.7890 - loss: 0.4771 - val_accuracy: 0.8730 - val_loss: 0.3244\n",
            "Epoch 3/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.8893 - loss: 0.2974 - val_accuracy: 0.8896 - val_loss: 0.2933\n",
            "Epoch 4/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.9200 - loss: 0.2335 - val_accuracy: 0.8934 - val_loss: 0.2822\n",
            "Epoch 5/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.9342 - loss: 0.1941 - val_accuracy: 0.8850 - val_loss: 0.2927\n",
            "Epoch 6/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.9543 - loss: 0.1529 - val_accuracy: 0.8897 - val_loss: 0.3024\n",
            "Epoch 7/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.9685 - loss: 0.1215 - val_accuracy: 0.8896 - val_loss: 0.3121\n",
            "Epoch 8/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.9762 - loss: 0.1009 - val_accuracy: 0.8872 - val_loss: 0.3418\n",
            "Epoch 9/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.9837 - loss: 0.0817 - val_accuracy: 0.8850 - val_loss: 0.3730\n",
            "Epoch 10/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.9887 - loss: 0.0701 - val_accuracy: 0.8807 - val_loss: 0.3632\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8809 - loss: 0.3632\n",
            "Test Loss: 0.3631693720817566, Test Accuracy: 0.8806800246238708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gRQF5Eov3VTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINE-GRAINED C-LSTM ON IMDB"
      ],
      "metadata": {
        "id": "ImW64jIE3U-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "# Function to simulate fine-grained labels (Here, we use a placeholder for fine-grained sentiment)\n",
        "# You need a dataset with true fine-grained labels, but for simulation, we'll bin binary labels into 5 classes\n",
        "def convert_to_fine_grained_labels(binary_labels, n_classes=5):\n",
        "    est = KBinsDiscretizer(n_bins=n_classes, encode='ordinal', strategy='uniform')\n",
        "    fine_grained_labels = est.fit_transform(binary_labels.reshape(-1, 1))\n",
        "    return fine_grained_labels.astype(int).reshape(-1)\n",
        "\n",
        "# C-LSTM with the embedding layer and pre-trained glove embeddings\n",
        "class CLSTMFineGrainedClassifier(tf.keras.Model):\n",
        "    def __init__(self, config, embedding_matrix):\n",
        "        super(CLSTMFineGrainedClassifier, self).__init__()\n",
        "        self.max_length = config.max_length\n",
        "        self.num_classes = config.num_classes\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.embedding_size = config.embedding_size\n",
        "        self.filter_sizes = list(map(int, config.filter_sizes.split(\",\")))\n",
        "        self.num_filters = config.num_filters\n",
        "        self.num_layers = config.num_layers\n",
        "        self.hidden_size = len(self.filter_sizes) * self.num_filters\n",
        "        self.l2_reg_lambda = config.l2_reg_lambda\n",
        "\n",
        "        # Embedding layer initialized with glove embeddings\n",
        "        self.embedding = layers.Embedding(input_dim=self.vocab_size,\n",
        "                                          output_dim=self.embedding_size,\n",
        "                                          input_length=self.max_length,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          trainable=True)\n",
        "\n",
        "        # Conv layers for different filter sizes\n",
        "        self.conv_layers = [\n",
        "            layers.Conv2D(filters=self.num_filters,\n",
        "                          kernel_size=(filter_size, self.embedding_size),\n",
        "                          activation='relu', padding='valid')\n",
        "            for filter_size in self.filter_sizes\n",
        "        ]\n",
        "\n",
        "        # LSTM layer\n",
        "        self.lstm = layers.LSTM(self.hidden_size, return_sequences=False)\n",
        "\n",
        "        self.dropout = layers.Dropout(rate=config.keep_prob)\n",
        "\n",
        "        # Final output layer for fine-grained classification (5 classes)\n",
        "        self.fc = layers.Dense(self.num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(self.l2_reg_lambda))\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        input_x = inputs\n",
        "        x = self.embedding(input_x)  # [batch_size, max_length, embedding_size]\n",
        "        x = tf.expand_dims(x, -1)    # [batch_size, max_length, embedding_size, 1]\n",
        "\n",
        "        conv_outputs = []\n",
        "        for conv_layer in self.conv_layers:\n",
        "            conv = conv_layer(x)\n",
        "            conv = tf.squeeze(conv, 2)  # squeezing out the 'channels' dimension\n",
        "            conv_outputs.append(conv)\n",
        "\n",
        "        # The minimum sequence length across all convolution outputs\n",
        "        min_length = min([conv.shape[1] for conv in conv_outputs])\n",
        "\n",
        "        # Trimming all convolution outputs to the same sequence length\n",
        "        conv_outputs = [conv[:, :min_length, :] for conv in conv_outputs]\n",
        "\n",
        "        if len(conv_outputs) > 1:\n",
        "            rnn_inputs = tf.concat(conv_outputs, -1)  # Concatenate along the last dimension\n",
        "        else:\n",
        "            rnn_inputs = conv_outputs[0]\n",
        "\n",
        "        # Feed to the LSTM\n",
        "        rnn_outputs = self.lstm(rnn_inputs)\n",
        "\n",
        "        rnn_outputs = self.dropout(rnn_outputs, training=training)\n",
        "\n",
        "        # Final output layer for fine-grained classification\n",
        "        logits = self.fc(rnn_outputs)\n",
        "        return logits\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "MAX_LEN = 500  # Max length of sequences (padded or truncated)\n",
        "VOCAB_SIZE = 5000  # The vocabulary\n",
        "EMBEDDING_DIM = 300  # GloVe embedding dimensions\n",
        "NUM_CLASSES = 5  # Number of fine-grained sentiment classes (Very Negative, Negative, Neutral, Positive, Very Positive)\n",
        "\n",
        "# Load the IMDb dataset\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=VOCAB_SIZE)\n",
        "\n",
        "# Simulate fine-grained labels (binned into 5 classes)\n",
        "y_train_fine = convert_to_fine_grained_labels(y_train)\n",
        "y_test_fine = convert_to_fine_grained_labels(y_test)\n",
        "\n",
        "# Padding the sequences to ensure uniform input size\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=MAX_LEN)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=MAX_LEN)\n",
        "\n",
        "def load_glove_embeddings(glove_file_path, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding_vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = embedding_vector\n",
        "    return embeddings_index\n",
        "\n",
        "def create_embedding_matrix(word_index, glove_embeddings, vocab_size, embedding_dim):\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i < vocab_size:  # Only consider the top 'vocab_size' words\n",
        "            embedding_vector = glove_embeddings.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "glove_file_path = '/content/drive/MyDrive/glove/glove.6B.300d.txt'\n",
        "glove_embeddings = load_glove_embeddings(glove_file_path, EMBEDDING_DIM)\n",
        "\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "embedding_matrix = create_embedding_matrix(word_index, glove_embeddings, VOCAB_SIZE, EMBEDDING_DIM)\n",
        "\n",
        "# Config for fine-grained classification\n",
        "class Config:\n",
        "    max_length = MAX_LEN\n",
        "    num_classes = NUM_CLASSES  # Fine-grained classification (5 classes)\n",
        "    vocab_size = VOCAB_SIZE\n",
        "    embedding_size = EMBEDDING_DIM  # GloVe embedding dimension\n",
        "    filter_sizes = \"3,4,5\"\n",
        "    num_filters = 64\n",
        "    num_layers = 1\n",
        "    l2_reg_lambda = 0.1\n",
        "    keep_prob = 0.5\n",
        "\n",
        "config = Config()\n",
        "model = CLSTMFineGrainedClassifier(config, embedding_matrix)\n",
        "\n",
        "# Compile model for fine-grained classification\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train_fine,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test_fine),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test_fine)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd92V8ul3XOX",
        "outputId": "897d0220-9230-49cc-d7d4-f11fcd9490f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 35ms/step - accuracy: 0.5528 - loss: 1.1647 - val_accuracy: 0.7341 - val_loss: 0.6335\n",
            "Epoch 2/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.7707 - loss: 0.5450 - val_accuracy: 0.8513 - val_loss: 0.4060\n",
            "Epoch 3/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.8844 - loss: 0.3435 - val_accuracy: 0.8850 - val_loss: 0.3313\n",
            "Epoch 4/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.9202 - loss: 0.2629 - val_accuracy: 0.8920 - val_loss: 0.3226\n",
            "Epoch 5/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.9398 - loss: 0.2177 - val_accuracy: 0.8846 - val_loss: 0.3395\n",
            "Epoch 6/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.9568 - loss: 0.1816 - val_accuracy: 0.8898 - val_loss: 0.3456\n",
            "Epoch 7/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.9701 - loss: 0.1446 - val_accuracy: 0.8791 - val_loss: 0.3901\n",
            "Epoch 8/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.9817 - loss: 0.1142 - val_accuracy: 0.8830 - val_loss: 0.3856\n",
            "Epoch 9/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.9894 - loss: 0.0919 - val_accuracy: 0.8837 - val_loss: 0.4091\n",
            "Epoch 10/10\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 35ms/step - accuracy: 0.9906 - loss: 0.0819 - val_accuracy: 0.8789 - val_loss: 0.4155\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.8784 - loss: 0.4163\n",
            "Test Loss: 0.4155207872390747, Test Accuracy: 0.8788800239562988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KXN7nIQR3a_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fI3Zp2su31Bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BINARY C-LSTM ON SST"
      ],
      "metadata": {
        "id": "Q4YD-Pp94zzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install datasets"
      ],
      "metadata": {
        "id": "8xugbhpD5C1W"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load SST dataset from Hugging Face\n",
        "dataset = load_dataset(\"sst\", trust_remote_code=True)\n",
        "\n",
        "# Extract sentences and fine-grained labels\n",
        "train_sentences = dataset['train']['sentence']\n",
        "train_fine_labels = dataset['train']['label']\n",
        "\n",
        "valid_sentences = dataset['validation']['sentence']\n",
        "valid_fine_labels = dataset['validation']['label']\n",
        "\n",
        "test_sentences = dataset['test']['sentence']\n",
        "test_fine_labels = dataset['test']['label']\n",
        "\n",
        "# Convert fine-grained labels to binary labels for SST-2 (0: negative, 1: positive)\n",
        "def convert_to_binary_labels(labels):\n",
        "    binary_labels = [0 if label < 2 else 1 for label in labels]\n",
        "    return binary_labels\n",
        "\n",
        "# Convert labels for binary classification\n",
        "train_binary_labels = convert_to_binary_labels(train_fine_labels)\n",
        "valid_binary_labels = convert_to_binary_labels(valid_fine_labels)\n",
        "test_binary_labels = convert_to_binary_labels(test_fine_labels)\n",
        "\n",
        "# Tokenization and padding\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "MAX_LEN = 50  # Max sequence length\n",
        "\n",
        "# Updated Config with dynamic variables\n",
        "class Config:\n",
        "    def __init__(self, max_length, vocab_size, embedding_size=300, l2_reg_lambda=0.0015, keep_prob=0.6):\n",
        "        self.max_length = max_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size  # GloVe embedding dimension\n",
        "        self.l2_reg_lambda = l2_reg_lambda\n",
        "        self.keep_prob = keep_prob\n",
        "        self.num_classes = 2  # Binary classification (SST-2)\n",
        "\n",
        "config = Config(max_length=MAX_LEN, vocab_size=VOCAB_SIZE)\n",
        "\n",
        "# Convert sentences to sequences and pad them\n",
        "train_sequences = pad_sequences(tokenizer.texts_to_sequences(train_sentences), maxlen=MAX_LEN)\n",
        "valid_sequences = pad_sequences(tokenizer.texts_to_sequences(valid_sentences), maxlen=MAX_LEN)\n",
        "test_sequences = pad_sequences(tokenizer.texts_to_sequences(test_sentences), maxlen=MAX_LEN)\n",
        "\n",
        "# C-LSTM Model for Binary Classification (SST-2)\n",
        "class CLSTMBinaryClassifierSST(tf.keras.Model):\n",
        "    def __init__(self, config, embedding_matrix):\n",
        "        super(CLSTMBinaryClassifierSST, self).__init__()\n",
        "        self.max_length = config.max_length\n",
        "        self.embedding_size = config.embedding_size\n",
        "        self.num_filters = 150  # As per the paper\n",
        "        self.hidden_size = 150  # LSTM hidden units\n",
        "        self.l2_reg_lambda = config.l2_reg_lambda\n",
        "\n",
        "        # Embedding layer initialized with GloVe embeddings (trainable)\n",
        "        self.embedding = layers.Embedding(input_dim=config.vocab_size,\n",
        "                                          output_dim=config.embedding_size,\n",
        "                                          input_length=config.max_length,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          trainable=True)\n",
        "\n",
        "        # Dropout for embedding layer\n",
        "        self.embedding_dropout = layers.Dropout(rate=config.keep_prob)\n",
        "\n",
        "        # Single conv layer with filter size 3 + Batch Norm (No pooling as per the paper)\n",
        "        self.conv_layer = layers.Conv2D(filters=self.num_filters,\n",
        "                                        kernel_size=(3, config.embedding_size),\n",
        "                                        activation='relu', padding='valid')\n",
        "        self.batch_norm = layers.BatchNormalization()\n",
        "\n",
        "        # LSTM layer to capture long-term dependencies\n",
        "        self.lstm = layers.LSTM(self.hidden_size, return_sequences=False)\n",
        "\n",
        "        # Dropout after LSTM\n",
        "        self.dropout = layers.Dropout(rate=config.keep_prob)\n",
        "\n",
        "        # Output layer for binary classification (SST-2)\n",
        "        self.fc_binary = layers.Dense(2, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(self.l2_reg_lambda))\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.embedding(inputs)\n",
        "        x = self.embedding_dropout(x, training=training)\n",
        "        x = tf.expand_dims(x, -1)\n",
        "\n",
        "        # Apply convolution layer and batch normalization\n",
        "        conv = self.conv_layer(x)\n",
        "        conv = self.batch_norm(conv, training=training)\n",
        "        conv = tf.squeeze(conv, 2)\n",
        "\n",
        "        # Feed the convolution output to LSTM\n",
        "        rnn_outputs = self.lstm(conv)\n",
        "\n",
        "        # Apply dropout\n",
        "        rnn_outputs = self.dropout(rnn_outputs, training=training)\n",
        "\n",
        "        # Output for binary classification (SST-2)\n",
        "        binary_output = self.fc_binary(rnn_outputs)\n",
        "\n",
        "        return binary_output\n",
        "\n",
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(glove_file_path, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding_vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = embedding_vector\n",
        "    return embeddings_index\n",
        "\n",
        "# Create embedding matrix\n",
        "def create_embedding_matrix(word_index, glove_embeddings, vocab_size, embedding_dim):\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i < vocab_size:  # Only consider words in vocab\n",
        "            embedding_vector = glove_embeddings.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "# Load pre-trained GloVe embeddings\n",
        "glove_file_path = \"/content/drive/MyDrive/glove/glove.6B.300d.txt\"  # Update this path\n",
        "glove_embeddings = load_glove_embeddings(glove_file_path, embedding_dim=300)\n",
        "\n",
        "# Initialize the embedding matrix using the tokenizer word index\n",
        "embedding_matrix = create_embedding_matrix(tokenizer.word_index, glove_embeddings, VOCAB_SIZE, embedding_dim=300)\n",
        "\n",
        "# Train the model on SST (Binary classification: SST-2)\n",
        "def compile_and_train_model(config):\n",
        "    # Pass the pre-loaded embedding matrix\n",
        "    model = CLSTMBinaryClassifierSST(config, embedding_matrix=embedding_matrix)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "    # Compile the model for binary classification\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Convert labels to numpy arrays\n",
        "    train_binary_labels_np = np.array(train_binary_labels)\n",
        "    valid_binary_labels_np = np.array(valid_binary_labels)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        np.array(train_sequences),\n",
        "        train_binary_labels_np,\n",
        "        batch_size=64,\n",
        "        epochs=20,\n",
        "        validation_data=(np.array(valid_sequences), valid_binary_labels_np),\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train and evaluate the model\n",
        "model = compile_and_train_model(config)\n",
        "\n",
        "# Evaluate on test data\n",
        "test_binary_labels_np = np.array(test_binary_labels)\n",
        "test_loss, test_acc = model.evaluate(np.array(test_sequences), test_binary_labels_np)\n",
        "\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925,
          "referenced_widgets": [
            "e0dbf53625604542b59b63b1957539df",
            "94f69c0e9f014c96b886161c0c24d36c",
            "cd5ef57910d74dc8ba7e314f0392e9ee",
            "15711429ac6d41818d3d3f7de37b9f0b",
            "04c90029e657496b9048f2b59287a23e",
            "7ab241acc1dd4ba7b20b70319e596c35",
            "3ac2e17d9fa548bba67bf5a7c8739f07",
            "a0517566c6df43b1ab882a3c96c7a6c1",
            "c2fa5bd49c4846af938c86233961a5a0",
            "f4e029628caa4a8892da694d18d1992d",
            "603c8d0f7bfb4bf2b0c96df4315c9563",
            "03b0b77c79c3434bb9b8e8f5ee83bacc",
            "e964adeed9194b2ea7c85069b0ccd9bf",
            "9fe737afcfab45f7a8545119a92d24d6",
            "6ae2be4939094674804fd511a15bbb71",
            "f2ce504e2a614bc5a30a3e2c3b12ebc3",
            "61f6fc8d215648cd97d8aa629a8d17bb",
            "0a8dfd2ae49e4d1ab5760a436251a458",
            "e64f22ee29bc47f69b5f308297caaacd",
            "894e16942a6241308c358e68ae3e6e30",
            "2cfc99cc140b4d9aa7064dee3ec5c8b9",
            "ca8a30dac94e4e10b31741513d713b99",
            "2003aefbaf96452c912b4f9d0d16af5a",
            "22c3ec6f47b84913adf50f2ccf9acb38",
            "cef80e7c3f76434a82fc1a5f12959e52",
            "a092019d38b541228f53992f9014d670",
            "1013ee863177422488ff549d5c15b89e",
            "055fcd5ff04347778a9245350a8f7482",
            "a2051a99d4744ba1ab05763504d61053",
            "71f49407bb9f4f959f5dfa8328ee71d7",
            "a38b2cf930fd4c29a6f2622015e10fb9",
            "f8aa0eb220bf4e139d954d83131e534e",
            "1ea208ee763e4c15bbe1636f8a870d63",
            "618c931591cd49f693f6968d40a620df",
            "d2f5cc910c3d49c7aa39fc710672ac4a",
            "eb25ab79704d464e9f108dd5a72d50c8",
            "cb67f1c69e004c1ab14fa1bffcf8149a",
            "b55705984302438d86f8fa9341af333b",
            "9793ba96338341b19cb414e754f014fe",
            "3f63b1977d1048d4bfdb562370935130",
            "9aaf35371dc54a11bc25a370e413afb5",
            "c88e9008005e4873b717fe3e5e75b3f1",
            "8d822280e84c434899ce559e33e35f3b",
            "9e94ab67af6146bfa570417b4b69bfb4",
            "1c21faf4ee494142923b539699907d00",
            "0a61fd1cd7204de5901120d2838ad909",
            "f5ece8ac5df345bcb7e3ae3138c83015",
            "438c643d66a24b41b328243aff2f62e3",
            "97c5e614789146efbee7631d1232c949",
            "66fab172af8643aeb03b7924a45be51a",
            "fa56fd7783464f4bbe6b4de67b778d93",
            "0bb104889961463abd1935e8572a5071",
            "c9cabf4de7b242fbad49e0e1660ffca6",
            "e1558749faf74134a27a7a0ff5f85ed5",
            "0780afb80bb7485eb1d7e1ed36ca9f8a"
          ]
        },
        "id": "P6CMgADO40Pz",
        "outputId": "ce3bcc50-7ed8-4ab1-84f8-ac070b817d96"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/6.37M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0dbf53625604542b59b63b1957539df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/790k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03b0b77c79c3434bb9b8e8f5ee83bacc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/8544 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2003aefbaf96452c912b4f9d0d16af5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/1101 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "618c931591cd49f693f6968d40a620df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/2210 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c21faf4ee494142923b539699907d00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.9411 - loss: 0.1497 - val_accuracy: 1.0000 - val_loss: 0.3405\n",
            "Epoch 2/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9986 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 0.1571\n",
            "Epoch 3/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 1.0000 - val_loss: 0.0148\n",
            "Epoch 4/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 1.0000 - val_loss: 0.0060\n",
            "Epoch 5/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 0.0056\n",
            "Epoch 6/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0055\n",
            "Epoch 7/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0053\n",
            "Epoch 8/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 0.0052\n",
            "Epoch 9/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 1.0000 - val_loss: 0.0050\n",
            "Epoch 10/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
            "Epoch 11/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 0.0046\n",
            "Epoch 12/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
            "Epoch 13/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
            "Epoch 14/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
            "Epoch 15/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
            "Epoch 16/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
            "Epoch 17/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
            "Epoch 18/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
            "Epoch 19/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0031\n",
            "Epoch 20/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0029\n",
            "Test Loss: 0.002900304039940238, Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TxJY8Jib5BLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BINARY C-LSTM ON SST"
      ],
      "metadata": {
        "id": "2VRoK-195oi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load SST dataset from Hugging Face\n",
        "dataset = load_dataset(\"sst\")\n",
        "\n",
        "# Extract sentences and fine-grained labels for SST-5\n",
        "train_sentences = dataset['train']['sentence']\n",
        "train_fine_labels = dataset['train']['label']\n",
        "\n",
        "valid_sentences = dataset['validation']['sentence']\n",
        "valid_fine_labels = dataset['validation']['label']\n",
        "\n",
        "test_sentences = dataset['test']['sentence']\n",
        "test_fine_labels = dataset['test']['label']\n",
        "\n",
        "# Tokenization and padding\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "MAX_LEN = 50  # Max sequence length\n",
        "\n",
        "# Updated Config with dynamic variables for fine-grained classification\n",
        "class Config:\n",
        "    def __init__(self, max_length, vocab_size, embedding_size=300, l2_reg_lambda=0.0015, keep_prob=0.5):\n",
        "        self.max_length = max_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size  # GloVe embedding dimension\n",
        "        self.l2_reg_lambda = l2_reg_lambda\n",
        "        self.keep_prob = keep_prob\n",
        "        self.num_classes = 5  # Fine-grained classification (SST-5)\n",
        "\n",
        "config = Config(max_length=MAX_LEN, vocab_size=VOCAB_SIZE)\n",
        "\n",
        "# Convert sentences to sequences and pad them\n",
        "train_sequences = pad_sequences(tokenizer.texts_to_sequences(train_sentences), maxlen=MAX_LEN)\n",
        "valid_sequences = pad_sequences(tokenizer.texts_to_sequences(valid_sentences), maxlen=MAX_LEN)\n",
        "test_sequences = pad_sequences(tokenizer.texts_to_sequences(test_sentences), maxlen=MAX_LEN)\n",
        "\n",
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(glove_file_path, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding_vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = embedding_vector\n",
        "    return embeddings_index\n",
        "\n",
        "# Create embedding matrix\n",
        "def create_embedding_matrix(word_index, glove_embeddings, vocab_size, embedding_dim):\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i < vocab_size:  # Only consider words in vocab\n",
        "            embedding_vector = glove_embeddings.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "# Load pre-trained GloVe embeddings\n",
        "glove_file_path = \"/content/drive/MyDrive/glove/glove.6B.300d.txt\"  # Update the path\n",
        "glove_embeddings = load_glove_embeddings(glove_file_path, embedding_dim=300)\n",
        "\n",
        "# Initialize the embedding matrix using the tokenizer word index\n",
        "embedding_matrix = create_embedding_matrix(tokenizer.word_index, glove_embeddings, VOCAB_SIZE, embedding_dim=300)\n",
        "\n",
        "# C-LSTM Model for Fine-Grained Classification (SST-5)\n",
        "class CLSTMFineGrainedClassifierSST(tf.keras.Model):\n",
        "    def __init__(self, config, embedding_matrix):\n",
        "        super(CLSTMFineGrainedClassifierSST, self).__init__()\n",
        "        self.max_length = config.max_length\n",
        "        self.embedding_size = config.embedding_size\n",
        "        self.num_filters = 150  # As per the paper\n",
        "        self.hidden_size = 150  # LSTM hidden units\n",
        "        self.l2_reg_lambda = config.l2_reg_lambda\n",
        "\n",
        "        # Embedding layer initialized with GloVe embeddings (trainable)\n",
        "        self.embedding = layers.Embedding(input_dim=config.vocab_size,\n",
        "                                          output_dim=config.embedding_size,\n",
        "                                          input_length=config.max_length,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          trainable=True)\n",
        "\n",
        "        # Dropout for embedding layer\n",
        "        self.embedding_dropout = layers.Dropout(rate=config.keep_prob)\n",
        "\n",
        "        # Single conv layer with filter size 3 + Batch Norm (No pooling as per the paper)\n",
        "        self.conv_layer = layers.Conv2D(filters=self.num_filters,\n",
        "                                        kernel_size=(3, config.embedding_size),\n",
        "                                        activation='relu', padding='valid')\n",
        "        self.batch_norm = layers.BatchNormalization()\n",
        "\n",
        "        # LSTM layer to capture long-term dependencies\n",
        "        self.lstm = layers.LSTM(self.hidden_size, return_sequences=False)\n",
        "\n",
        "        # Dropout after LSTM\n",
        "        self.dropout = layers.Dropout(rate=config.keep_prob)\n",
        "\n",
        "        # Output layer for fine-grained classification (SST-5)\n",
        "        self.fc_fine = layers.Dense(5, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(self.l2_reg_lambda))\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.embedding(inputs)\n",
        "        x = self.embedding_dropout(x, training=training)\n",
        "        x = tf.expand_dims(x, -1)\n",
        "\n",
        "        # Apply convolution layer and batch normalization\n",
        "        conv = self.conv_layer(x)\n",
        "        conv = self.batch_norm(conv, training=training)\n",
        "        conv = tf.squeeze(conv, 2)\n",
        "\n",
        "        # Feed the convolution output to LSTM\n",
        "        rnn_outputs = self.lstm(conv)\n",
        "\n",
        "        # Apply dropout\n",
        "        rnn_outputs = self.dropout(rnn_outputs, training=training)\n",
        "\n",
        "        # Output for fine-grained classification (SST-5)\n",
        "        fine_output = self.fc_fine(rnn_outputs)\n",
        "\n",
        "        return fine_output\n",
        "\n",
        "# Train the model on SST (Fine-Grained Classification: SST-5)\n",
        "def compile_and_train_model(config):\n",
        "    # Pass the pre-loaded embedding matrix\n",
        "    model = CLSTMFineGrainedClassifierSST(config, embedding_matrix=embedding_matrix)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "    # Compile the model for fine-grained classification (5 classes)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Convert labels to numpy arrays\n",
        "    train_fine_labels_np = np.array(train_fine_labels)\n",
        "    valid_fine_labels_np = np.array(valid_fine_labels)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(\n",
        "        np.array(train_sequences),\n",
        "        train_fine_labels_np,\n",
        "        batch_size=64,\n",
        "        epochs=20,\n",
        "        validation_data=(np.array(valid_sequences), valid_fine_labels_np),\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train and evaluate the model\n",
        "model = compile_and_train_model(config)\n",
        "\n",
        "# Evaluate on test data\n",
        "test_fine_labels_np = np.array(test_fine_labels)\n",
        "test_loss, test_acc = model.evaluate(np.array(test_sequences), test_fine_labels_np)\n",
        "\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqyaPnOG5qG3",
        "outputId": "5223b1f2-e078-4d2e-8a62-0554b559b968"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.0016 - loss: 0.3100 - val_accuracy: 0.0036 - val_loss: 0.8444\n",
            "Epoch 2/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0012 - loss: 0.0353 - val_accuracy: 0.0036 - val_loss: 0.5418\n",
            "Epoch 3/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0023 - loss: 0.0296 - val_accuracy: 0.0036 - val_loss: 0.0826\n",
            "Epoch 4/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0019 - loss: 0.0342 - val_accuracy: 0.0036 - val_loss: 0.0442\n",
            "Epoch 5/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0023 - loss: 0.0249 - val_accuracy: 0.0036 - val_loss: 0.0418\n",
            "Epoch 6/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0021 - loss: 0.0258 - val_accuracy: 0.0036 - val_loss: 0.0420\n",
            "Epoch 7/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0017 - loss: 0.0204 - val_accuracy: 0.0036 - val_loss: 0.0414\n",
            "Epoch 8/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0019 - loss: 0.0208 - val_accuracy: 0.0036 - val_loss: 0.0446\n",
            "Epoch 9/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.0180 - val_accuracy: 0.0036 - val_loss: 0.0473\n",
            "Epoch 10/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.0170 - val_accuracy: 0.0036 - val_loss: 0.0455\n",
            "Epoch 11/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0036 - loss: 0.0151 - val_accuracy: 0.0036 - val_loss: 0.0492\n",
            "Epoch 12/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0029 - loss: 0.0127 - val_accuracy: 0.0036 - val_loss: 0.0501\n",
            "Epoch 13/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0034 - loss: 0.0119 - val_accuracy: 0.0036 - val_loss: 0.0477\n",
            "Epoch 14/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0028 - loss: 0.0117 - val_accuracy: 0.0036 - val_loss: 0.0500\n",
            "Epoch 15/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0035 - loss: 0.0105 - val_accuracy: 0.0036 - val_loss: 0.0497\n",
            "Epoch 16/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0043 - loss: 0.0099 - val_accuracy: 0.0036 - val_loss: 0.0526\n",
            "Epoch 17/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0040 - loss: 0.0087 - val_accuracy: 0.0036 - val_loss: 0.0523\n",
            "Epoch 18/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0043 - loss: 0.0095 - val_accuracy: 0.0036 - val_loss: 0.0488\n",
            "Epoch 19/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0042 - loss: 0.0092 - val_accuracy: 0.0036 - val_loss: 0.0533\n",
            "Epoch 20/20\n",
            "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0036 - loss: 0.0082 - val_accuracy: 0.0036 - val_loss: 0.0499\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.7263e-04 - loss: 0.0300\n",
            "Test Loss: 0.024721022695302963, Test Accuracy: 0.0013574660988524556\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u-wngMvc8A8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iDVSq4f4JGz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "BINARY C-LSTM ON SST AMAZON REVIEWS DATASET"
      ],
      "metadata": {
        "id": "dX-OS3MJJROV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# C-LSTM with the embedding layer with the pre-trained glove embeddings\n",
        "class CLSTMBinaryAmazonReviewsClassifier(tf.keras.Model):\n",
        "    def __init__(self, config, embedding_matrix):\n",
        "        super(CLSTMBinaryAmazonReviewsClassifier, self).__init__()\n",
        "        self.max_length = config.max_length\n",
        "        self.num_classes = config.num_classes\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.embedding_size = config.embedding_size\n",
        "        self.filter_sizes = list(map(int, config.filter_sizes.split(\",\")))\n",
        "        self.num_filters = config.num_filters\n",
        "        self.num_layers = config.num_layers\n",
        "        self.hidden_size = len(self.filter_sizes) * self.num_filters\n",
        "        self.l2_reg_lambda = config.l2_reg_lambda\n",
        "\n",
        "        # embedding layer initialized with glove embeddings\n",
        "        self.embedding = layers.Embedding(input_dim=self.vocab_size,\n",
        "                                          output_dim=self.embedding_size,\n",
        "                                          input_length=self.max_length,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          trainable=True)\n",
        "\n",
        "        # conv layers for different filter sizes\n",
        "        self.conv_layers = [\n",
        "            layers.Conv2D(filters=self.num_filters,\n",
        "                          kernel_size=(filter_size, self.embedding_size),\n",
        "                          activation='relu', padding='valid')\n",
        "            for filter_size in self.filter_sizes\n",
        "        ]\n",
        "\n",
        "        # lstm layer\n",
        "        self.lstm = layers.LSTM(self.hidden_size, return_sequences=False)\n",
        "\n",
        "        self.dropout = layers.Dropout(rate=config.keep_prob)\n",
        "\n",
        "        self.fc = layers.Dense(self.num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(self.l2_reg_lambda))\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        input_x = inputs\n",
        "        x = self.embedding(input_x)  # [batch_size, max_length, embedding_size]\n",
        "        x = tf.expand_dims(x, -1)    # [batch_size, max_length, embedding_size, 1]\n",
        "\n",
        "        conv_outputs = []\n",
        "        for conv_layer in self.conv_layers:\n",
        "            conv = conv_layer(x)\n",
        "            conv = tf.squeeze(conv, 2)  # squeezing out the 'channels' dimension\n",
        "            conv_outputs.append(conv)\n",
        "\n",
        "        # the minimum sequence length across all convolution outputs\n",
        "        min_length = min([conv.shape[1] for conv in conv_outputs])\n",
        "\n",
        "        # trimmikng all convolution outputs to the same sequence length\n",
        "        conv_outputs = [conv[:, :min_length, :] for conv in conv_outputs]\n",
        "\n",
        "        if len(conv_outputs) > 1:\n",
        "            rnn_inputs = tf.concat(conv_outputs, -1)  # concat along the last dimension\n",
        "        else:\n",
        "            rnn_inputs = conv_outputs[0]\n",
        "\n",
        "        # feed it to the LSTM\n",
        "        rnn_outputs = self.lstm(rnn_inputs)\n",
        "\n",
        "        rnn_outputs = self.dropout(rnn_outputs, training=training)\n",
        "\n",
        "        # final output layer\n",
        "        logits = self.fc(rnn_outputs)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "846C6G2gJlBQ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "MAX_LEN = 500  # max length of sequences (padded or truncated)\n",
        "VOCAB_SIZE = 5000  # the vocabulary\n",
        "EMBEDDING_DIM = 300  # glove embedding dimensions"
      ],
      "metadata": {
        "id": "fLbmN1LdJryk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "\n",
        "dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_All_Beauty\", trust_remote_code=True)\n",
        "\n",
        "reviews = [item['text'] for item in dataset['full']]\n",
        "labels = [1 if item['rating'] >= 3 else 0 for item in dataset['full']]\n",
        "\n",
        "print(f\"First review: {reviews[0]}\")\n",
        "print(f\"First label: {labels[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199,
          "referenced_widgets": [
            "95b079e00e2f4d0280332124d423f154",
            "adbc5bbeb85641f38a0a1df31e90a064",
            "7d6352ced01d493083ad6258b76b7941",
            "a13601f49b3b4a7ebc0840621a668976",
            "29b3eecb451343a3b644e90606482e9b",
            "8d68a2275aa241889a8e8183d8d242b0",
            "23d61c515a534845909ee05a249be309",
            "1198bdd69d2b42d8a4c21290ea948732",
            "3cce705f0b7e420bb3d26c134550b1e0",
            "b4214dc1c0974ecaa2bad02222c0092b",
            "3bd681ba074446dc9a25d48699986cb6",
            "d51914f5006047a09bbe3907256c73d0",
            "71f92b756aa544f6819453d7f4a87275",
            "3a4c30222cd1441b914128be88680921",
            "1d34bbda59b14a6cbe9892388f9bbe58",
            "91e48920dea6485ab43ebbf177181074",
            "503b86ce45ce4d04a4f25e597b623e61",
            "dfe8544855844c03af54ce9d19e43bdc",
            "b592f895cbf94cc59b0f3f848f65a3c2",
            "58c75ed299344e4eae358658b30cf4a1",
            "580b7b229901427fb5d3186bc40fab76",
            "e6e18ee3788b42c5886638f203ba5a81",
            "deac4c1bf0984e2bb0f0f733c7eb481a",
            "51f7e2727166411d8b97e44de706d4a5",
            "8b091cfb9e9b42718ed52bf2b76cf572",
            "9e2787fd87034043b85e4703dcd2523e",
            "95065fd8fd5744f3a4167259ee8281af",
            "8342bd08e0824656b9dac9d92cc46882",
            "eaed1fc1b283415ba2d28d58666a29a4",
            "74b16dda9557440695257c8843916452",
            "cf84583ddea04080a8ded280eff084f0",
            "a0b1cc050df045f3bc886f5a1454e027",
            "361f9efed80945c08f441898320aa416",
            "0eaaf15400874f7a880d658c0e1d75b4",
            "8aed96563b754f3ebed7ea22c257c16c",
            "50b5af3114204cc896a10770841238df",
            "16b62f9463d5444db52315c8992647e9",
            "153c490e2ac2449ab207f17f19a1c39b",
            "68e76bd8a02d42de84b4adaa7855a46e",
            "88d9983be3794bfa9560bfb1933cd73b",
            "b9002c011ba74d8db5a5b2dc532e5564",
            "cca0e076ccba43fe99486eb6577bea16",
            "a2343e04b1464844a251853897253055",
            "036b2df7d5334e6a8e26a545be1f507e"
          ]
        },
        "id": "v_EQhmQgJxwH",
        "outputId": "6d52a779-095f-457d-9a1c-57e01a2847f4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Amazon-Reviews-2023.py:   0%|          | 0.00/39.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95b079e00e2f4d0280332124d423f154"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/19.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d51914f5006047a09bbe3907256c73d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "All_Beauty.jsonl:   0%|          | 0.00/327M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "deac4c1bf0984e2bb0f0f733c7eb481a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating full split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0eaaf15400874f7a880d658c0e1d75b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First review: This spray is really nice. It smells really good, goes on really fine, and does the trick. I will say it feels like you need a lot of it though to get the texture I want. I have a lot of hair, medium thickness. I am comparing to other brands with yucky chemicals so I'm gonna stick with this. Try it!\n",
            "First label: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "review_lengths = [len(review.split()) for review in reviews]\n",
        "avg_review_length = np.mean(review_lengths)\n",
        "max_review_length = np.max(review_lengths)\n",
        "print(f\"Average review length: {avg_review_length}\")\n",
        "print(f\"Maximum review length: {max_review_length}\")\n",
        "\n",
        "tokeniser = Tokenizer()\n",
        "tokeniser.fit_on_texts(reviews)\n",
        "total_unique_words = len(tokeniser.word_index)\n",
        "print(f\"Total unique words in the dataset: {total_unique_words}\")\n",
        "\n",
        "\n",
        "import collections\n",
        "rating_distribution = collections.Counter([item['rating'] for item in dataset['full']])\n",
        "print(f\"Rating distribution: {rating_distribution}\")"
      ],
      "metadata": {
        "id": "JoJNgNSOJyKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "tokeniser = Tokenizer(num_words=10000)  # setting vocab_size to 10,000 as per the updated config\n",
        "tokeniser.fit_on_texts(reviews)  # fitting the tokeniser on the Amazon reviews dataset\n",
        "sequences = tokeniser.texts_to_sequences(reviews)\n",
        "\n",
        "# pad the sequences to the max length of 300\n",
        "x_data = pad_sequences(sequences, maxlen=300)\n",
        "\n",
        "# labels to numpy array\n",
        "y_data = np.array(labels)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "def load_glove_embeddings(glove_file_path, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding_vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = embedding_vector\n",
        "    return embeddings_index\n",
        "\n",
        "def create_embedding_matrix(word_index, glove_embeddings, vocab_size, embedding_dim):\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i < vocab_size:  # Only consider the top 'vocab_size' words\n",
        "            embedding_vector = glove_embeddings.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                # Words not found in the embedding index will be all zeros.\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "glove_file_path = '/content/drive/MyDrive/glove/glove.6B.300d.txt'\n",
        "glove_embeddings = load_glove_embeddings(glove_file_path, 300)\n",
        "\n",
        "# embedding matrix\n",
        "word_index = tokenizer.word_index\n",
        "embedding_matrix = create_embedding_matrix(word_index, glove_embeddings, 10000, 300)\n",
        "\n",
        "class Config:\n",
        "    max_length = 300  # based on the average review length analysis\n",
        "    num_classes = 2  # binary classification (positive/negative)\n",
        "    vocab_size = 10000  # limit vocabulary size to top 10,000 words\n",
        "    embedding_size = 300  #  300-dimensional GloVe embeddings\n",
        "    filter_sizes = \"3,4,5\"  # convolution filter sizes\n",
        "    num_filters = 64  # num of filters for each filter size\n",
        "    num_layers = 1  #  lstm layer\n",
        "    l2_reg_lambda = 0.1  # L2 regularisation to prevent overfitting\n",
        "    keep_prob = 0.5  # dropout probability\n",
        "\n",
        "# init the C-LSTM model with the updated configuration and embedding matrix\n",
        "config = Config()\n",
        "model = CLSTMBinaryAmazonReviewsClassifier(config, embedding_matrix)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u81NzdnJ5KF",
        "outputId": "dff24775-4b81-4029-cd80-0868707f99df"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 18ms/step - accuracy: 0.8900 - loss: 0.2832 - val_accuracy: 0.9227 - val_loss: 0.1947\n",
            "Epoch 2/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 17ms/step - accuracy: 0.9297 - loss: 0.1810 - val_accuracy: 0.9247 - val_loss: 0.1909\n",
            "Epoch 3/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 17ms/step - accuracy: 0.9368 - loss: 0.1654 - val_accuracy: 0.9267 - val_loss: 0.1940\n",
            "Epoch 4/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 17ms/step - accuracy: 0.9435 - loss: 0.1517 - val_accuracy: 0.9260 - val_loss: 0.1932\n",
            "Epoch 5/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 17ms/step - accuracy: 0.9496 - loss: 0.1399 - val_accuracy: 0.9229 - val_loss: 0.1973\n",
            "Epoch 6/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 17ms/step - accuracy: 0.9546 - loss: 0.1287 - val_accuracy: 0.9229 - val_loss: 0.2061\n",
            "Epoch 7/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 17ms/step - accuracy: 0.9599 - loss: 0.1186 - val_accuracy: 0.9222 - val_loss: 0.2020\n",
            "Epoch 8/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 17ms/step - accuracy: 0.9638 - loss: 0.1101 - val_accuracy: 0.9205 - val_loss: 0.2139\n",
            "Epoch 9/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 17ms/step - accuracy: 0.9666 - loss: 0.1046 - val_accuracy: 0.9199 - val_loss: 0.2278\n",
            "Epoch 10/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 17ms/step - accuracy: 0.9697 - loss: 0.0971 - val_accuracy: 0.9195 - val_loss: 0.2280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-itEYiXJ5jw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINE-GRAINED C-LSTM ON AMAZON REVIEWS DATASET"
      ],
      "metadata": {
        "id": "Z8-b5hvbNvcZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# C-LSTM for Fine-Grained Classification with GloVe embeddings\n",
        "class CLSTMFineGrainedAmazonReviewsClassifier(tf.keras.Model):\n",
        "    def __init__(self, config, embedding_matrix):\n",
        "        super(CLSTMFineGrainedAmazonReviewsClassifier, self).__init__()\n",
        "        self.max_length = config.max_length\n",
        "        self.num_classes = config.num_classes\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.embedding_size = config.embedding_size\n",
        "        self.filter_sizes = list(map(int, config.filter_sizes.split(\",\")))\n",
        "        self.num_filters = config.num_filters\n",
        "        self.num_layers = config.num_layers\n",
        "        self.hidden_size = len(self.filter_sizes) * self.num_filters\n",
        "        self.l2_reg_lambda = config.l2_reg_lambda\n",
        "\n",
        "        # embedding layer initialized with GloVe embeddings\n",
        "        self.embedding = layers.Embedding(input_dim=self.vocab_size,\n",
        "                                          output_dim=self.embedding_size,\n",
        "                                          input_length=self.max_length,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          trainable=True)\n",
        "\n",
        "        # conv layers for different filter sizes\n",
        "        self.conv_layers = [\n",
        "            layers.Conv2D(filters=self.num_filters,\n",
        "                          kernel_size=(filter_size, self.embedding_size),\n",
        "                          activation='relu', padding='valid')\n",
        "            for filter_size in self.filter_sizes\n",
        "        ]\n",
        "\n",
        "        # lstm layer\n",
        "        self.lstm = layers.LSTM(self.hidden_size, return_sequences=False)\n",
        "\n",
        "        self.dropout = layers.Dropout(rate=config.keep_prob)\n",
        "\n",
        "        self.fc = layers.Dense(self.num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(self.l2_reg_lambda))\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        input_x = inputs\n",
        "        x = self.embedding(input_x)  # [batch_size, max_length, embedding_size]\n",
        "        x = tf.expand_dims(x, -1)    # [batch_size, max_length, embedding_size, 1]\n",
        "\n",
        "        conv_outputs = []\n",
        "        for conv_layer in self.conv_layers:\n",
        "            conv = conv_layer(x)\n",
        "            conv = tf.squeeze(conv, 2)  # squeezing out the 'channels' dimension\n",
        "            conv_outputs.append(conv)\n",
        "\n",
        "        # the minimum sequence length across all convolution outputs\n",
        "        min_length = min([conv.shape[1] for conv in conv_outputs])\n",
        "\n",
        "        # trimming all convolution outputs to the same sequence length\n",
        "        conv_outputs = [conv[:, :min_length, :] for conv in conv_outputs]\n",
        "\n",
        "        if len(conv_outputs) > 1:\n",
        "            rnn_inputs = tf.concat(conv_outputs, -1)  # concat along the last dimension\n",
        "        else:\n",
        "            rnn_inputs = conv_outputs[0]\n",
        "\n",
        "        # feed it to the LSTM\n",
        "        rnn_outputs = self.lstm(rnn_inputs)\n",
        "\n",
        "        rnn_outputs = self.dropout(rnn_outputs, training=training)\n",
        "\n",
        "        # final output layer\n",
        "        logits = self.fc(rnn_outputs)\n",
        "        return logits\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "MAX_LEN = 300  # max length of sequences (padded or truncated)\n",
        "VOCAB_SIZE = 10000  # vocabulary size\n",
        "EMBEDDING_DIM = 300  # GloVe embedding dimensions\n",
        "\n",
        "# Tokenizer and padding\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(reviews)  # assuming `reviews` contains the Amazon reviews text\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(reviews)\n",
        "x_data = pad_sequences(sequences, maxlen=MAX_LEN)\n",
        "\n",
        "# Labels for fine-grained classification (assuming labels contain ratings 1 to 5)\n",
        "y_data = np.array(labels)\n",
        "\n",
        "# Splitting the data\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(glove_file_path, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding_vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = embedding_vector\n",
        "    return embeddings_index\n",
        "\n",
        "def create_embedding_matrix(word_index, glove_embeddings, vocab_size, embedding_dim):\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i < vocab_size:  # Only consider the top 'vocab_size' words\n",
        "            embedding_vector = glove_embeddings.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "# Path to the GloVe embeddings\n",
        "glove_file_path = '/content/drive/MyDrive/glove/glove.6B.300d.txt'\n",
        "glove_embeddings = load_glove_embeddings(glove_file_path, EMBEDDING_DIM)\n",
        "\n",
        "# Create embedding matrix\n",
        "word_index = tokenizer.word_index\n",
        "embedding_matrix = create_embedding_matrix(word_index, glove_embeddings, VOCAB_SIZE, EMBEDDING_DIM)\n",
        "\n",
        "# Configuration for fine-grained classification\n",
        "class Config:\n",
        "    max_length = MAX_LEN\n",
        "    num_classes = 5  # Fine-grained classification (1 to 5 stars)\n",
        "    vocab_size = VOCAB_SIZE\n",
        "    embedding_size = EMBEDDING_DIM  # GloVe embedding dimensions\n",
        "    filter_sizes = \"3,4,5\"\n",
        "    num_filters = 64\n",
        "    num_layers = 1\n",
        "    l2_reg_lambda = 0.1\n",
        "    keep_prob = 0.5\n",
        "\n",
        "# Initialize the model\n",
        "config = Config()\n",
        "model = CLSTMFineGrainedAmazonReviewsClassifier(config, embedding_matrix)\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVOy3ycdKISk",
        "outputId": "b97270e3-d5bf-498c-c7f9-7040f062f990"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 17ms/step - accuracy: 0.8956 - loss: 0.3258 - val_accuracy: 0.9239 - val_loss: 0.1949\n",
            "Epoch 2/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 17ms/step - accuracy: 0.9295 - loss: 0.1848 - val_accuracy: 0.9265 - val_loss: 0.1906\n",
            "Epoch 3/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 17ms/step - accuracy: 0.9372 - loss: 0.1673 - val_accuracy: 0.9275 - val_loss: 0.1888\n",
            "Epoch 4/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 17ms/step - accuracy: 0.9436 - loss: 0.1545 - val_accuracy: 0.9272 - val_loss: 0.1918\n",
            "Epoch 5/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 17ms/step - accuracy: 0.9501 - loss: 0.1410 - val_accuracy: 0.9258 - val_loss: 0.1973\n",
            "Epoch 6/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 17ms/step - accuracy: 0.9557 - loss: 0.1291 - val_accuracy: 0.9241 - val_loss: 0.2079\n",
            "Epoch 7/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 17ms/step - accuracy: 0.9613 - loss: 0.1183 - val_accuracy: 0.9209 - val_loss: 0.2135\n",
            "Epoch 8/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 17ms/step - accuracy: 0.9664 - loss: 0.1083 - val_accuracy: 0.9221 - val_loss: 0.2200\n",
            "Epoch 9/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 17ms/step - accuracy: 0.9704 - loss: 0.0996 - val_accuracy: 0.9202 - val_loss: 0.2285\n",
            "Epoch 10/10\n",
            "\u001b[1m8770/8770\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 17ms/step - accuracy: 0.9732 - loss: 0.0930 - val_accuracy: 0.9185 - val_loss: 0.2352\n",
            "\u001b[1m4385/4385\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - accuracy: 0.9185 - loss: 0.2345\n",
            "Test Loss: 0.23521772027015686, Test Accuracy: 0.9185423254966736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WtKjiK5kQmpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "BINARY C-LSTM ON YELP DATASET"
      ],
      "metadata": {
        "id": "nU2ZXeNjZZQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datasets import load_dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load Yelp dataset from Hugging Face\n",
        "ds = load_dataset(\"yelp_review_full\", split='train')\n",
        "\n",
        "# Sample of the dataset\n",
        "reviews = ds['text']  # Extract reviews\n",
        "labels = ds['label']  # Extract ratings (0-4)\n",
        "\n",
        "# Convert ratings to binary labels (e.g., 1-3 stars = negative, 4-5 stars = positive)\n",
        "def convert_to_binary_labels(labels):\n",
        "    binary_labels = [1 if label >= 3 else 0 for label in labels]\n",
        "    return binary_labels\n",
        "\n",
        "binary_labels = convert_to_binary_labels(labels)\n",
        "\n",
        "# Tokenization and padding\n",
        "VOCAB_SIZE = 10000\n",
        "MAX_LEN = 300  # Max sequence length based on Yelp reviews\n",
        "\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(reviews)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(reviews)\n",
        "x_data = pad_sequences(sequences, maxlen=MAX_LEN)\n",
        "y_data = np.array(binary_labels)\n",
        "\n",
        "# Split data into training and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(glove_file_path, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding_vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = embedding_vector\n",
        "    return embeddings_index\n",
        "\n",
        "# Create embedding matrix\n",
        "def create_embedding_matrix(word_index, glove_embeddings, vocab_size, embedding_dim):\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i < vocab_size:\n",
        "            embedding_vector = glove_embeddings.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "# Path to GloVe embeddings file\n",
        "glove_file_path = '/content/drive/MyDrive/glove/glove.6B.300d.txt'\n",
        "glove_embeddings = load_glove_embeddings(glove_file_path, 300)\n",
        "embedding_matrix = create_embedding_matrix(tokenizer.word_index, glove_embeddings, VOCAB_SIZE, 300)\n",
        "\n",
        "# C-LSTM Model for Binary Classification\n",
        "class CLSTMBinaryYelpClassifier(tf.keras.Model):\n",
        "    def __init__(self, config, embedding_matrix):\n",
        "        super(CLSTMBinaryYelpClassifier, self).__init__()\n",
        "        self.max_length = config.max_length\n",
        "        self.num_classes = config.num_classes\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.embedding_size = config.embedding_size\n",
        "        self.filter_sizes = list(map(int, config.filter_sizes.split(\",\")))\n",
        "        self.num_filters = config.num_filters\n",
        "        self.hidden_size = len(self.filter_sizes) * self.num_filters\n",
        "        self.l2_reg_lambda = config.l2_reg_lambda\n",
        "\n",
        "        # Embedding layer initialized with GloVe embeddings\n",
        "        self.embedding = layers.Embedding(input_dim=self.vocab_size,\n",
        "                                          output_dim=self.embedding_size,\n",
        "                                          input_length=self.max_length,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          trainable=True)\n",
        "\n",
        "        # Convolutional layers for different filter sizes\n",
        "        self.conv_layers = [\n",
        "            layers.Conv2D(filters=self.num_filters,\n",
        "                          kernel_size=(filter_size, self.embedding_size),\n",
        "                          activation='relu', padding='valid')\n",
        "            for filter_size in self.filter_sizes\n",
        "        ]\n",
        "\n",
        "        # LSTM layer to capture dependencies\n",
        "        self.lstm = layers.LSTM(self.hidden_size, return_sequences=False)\n",
        "\n",
        "        self.dropout = layers.Dropout(rate=config.keep_prob)\n",
        "\n",
        "        # Fully connected layer for binary classification (2 classes)\n",
        "        self.fc = layers.Dense(self.num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(self.l2_reg_lambda))\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.embedding(inputs)  # [batch_size, max_length, embedding_size]\n",
        "        x = tf.expand_dims(x, -1)   # [batch_size, max_length, embedding_size, 1]\n",
        "\n",
        "        conv_outputs = []\n",
        "        for conv_layer in self.conv_layers:\n",
        "            conv = conv_layer(x)\n",
        "            conv = tf.squeeze(conv, 2)  # Squeeze channels dimension\n",
        "            conv_outputs.append(conv)\n",
        "\n",
        "        # Trimming all conv outputs to the same sequence length\n",
        "        min_length = min([conv.shape[1] for conv in conv_outputs])\n",
        "        conv_outputs = [conv[:, :min_length, :] for conv in conv_outputs]\n",
        "\n",
        "        # Concatenate conv outputs if more than one\n",
        "        if len(conv_outputs) > 1:\n",
        "            rnn_inputs = tf.concat(conv_outputs, -1)\n",
        "        else:\n",
        "            rnn_inputs = conv_outputs[0]\n",
        "\n",
        "        # LSTM layer\n",
        "        rnn_outputs = self.lstm(rnn_inputs)\n",
        "\n",
        "        # Apply dropout\n",
        "        rnn_outputs = self.dropout(rnn_outputs, training=training)\n",
        "\n",
        "        # Output layer (binary classification)\n",
        "        logits = self.fc(rnn_outputs)\n",
        "        return logits\n",
        "\n",
        "# Configuration for the model\n",
        "class Config:\n",
        "    max_length = 300\n",
        "    num_classes = 2  # Binary classification\n",
        "    vocab_size = VOCAB_SIZE\n",
        "    embedding_size = 300  # GloVe embeddings size\n",
        "    filter_sizes = \"3,4,5\"  # Convolution filter sizes\n",
        "    num_filters = 64  # Number of filters for each filter size\n",
        "    l2_reg_lambda = 0.1  # Regularization\n",
        "    keep_prob = 0.5  # Dropout probability\n",
        "\n",
        "# Instantiate config and the model\n",
        "config = Config()\n",
        "model = CLSTMBinaryYelpClassifier(config, embedding_matrix)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUAgPg5RZfma",
        "outputId": "d21bf146-cf08-4528-d631-68813f154cc2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 17ms/step - accuracy: 0.8496 - loss: 0.3712 - val_accuracy: 0.8927 - val_loss: 0.2601\n",
            "Epoch 2/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9029 - loss: 0.2446 - val_accuracy: 0.8999 - val_loss: 0.2451\n",
            "Epoch 3/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9147 - loss: 0.2197 - val_accuracy: 0.9021 - val_loss: 0.2462\n",
            "Epoch 4/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9242 - loss: 0.1992 - val_accuracy: 0.9016 - val_loss: 0.2445\n",
            "Epoch 5/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9335 - loss: 0.1802 - val_accuracy: 0.8997 - val_loss: 0.2502\n",
            "Epoch 6/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9421 - loss: 0.1621 - val_accuracy: 0.8986 - val_loss: 0.2586\n",
            "Epoch 7/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9492 - loss: 0.1468 - val_accuracy: 0.8957 - val_loss: 0.2793\n",
            "Epoch 8/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9549 - loss: 0.1348 - val_accuracy: 0.8959 - val_loss: 0.2896\n",
            "Epoch 9/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9593 - loss: 0.1256 - val_accuracy: 0.8912 - val_loss: 0.2964\n",
            "Epoch 10/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9623 - loss: 0.1181 - val_accuracy: 0.8908 - val_loss: 0.3098\n",
            "\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - accuracy: 0.8913 - loss: 0.3076\n",
            "Test Loss: 0.3098303973674774, Test Accuracy: 0.8907999992370605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PhSwYfQVZkbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINE-GRAINED C-LSTM ON YELP"
      ],
      "metadata": {
        "id": "lzlht6KphkJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datasets import load_dataset\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load Yelp dataset from Hugging Face\n",
        "ds = load_dataset(\"yelp_review_full\", split='train')\n",
        "\n",
        "# Sample of the dataset\n",
        "reviews = ds['text']  # Extract reviews\n",
        "labels = ds['label']  # Extract ratings (0-4)\n",
        "\n",
        "# Convert ratings to binary labels (e.g., 1-3 stars = negative, 4-5 stars = positive)\n",
        "def convert_to_binary_labels(labels):\n",
        "    binary_labels = [1 if label >= 3 else 0 for label in labels]\n",
        "    return binary_labels\n",
        "\n",
        "binary_labels = convert_to_binary_labels(labels)\n",
        "\n",
        "# Tokenization and padding\n",
        "VOCAB_SIZE = 10000\n",
        "MAX_LEN = 300  # Max sequence length based on Yelp reviews\n",
        "\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(reviews)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(reviews)\n",
        "x_data = pad_sequences(sequences, maxlen=MAX_LEN)\n",
        "y_data = np.array(binary_labels)\n",
        "\n",
        "# Split data into training and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(glove_file_path, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding_vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = embedding_vector\n",
        "    return embeddings_index\n",
        "\n",
        "# Create embedding matrix\n",
        "def create_embedding_matrix(word_index, glove_embeddings, vocab_size, embedding_dim):\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i < vocab_size:\n",
        "            embedding_vector = glove_embeddings.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "# Path to GloVe embeddings file\n",
        "glove_file_path = '/content/drive/MyDrive/glove/glove.6B.300d.txt'\n",
        "glove_embeddings = load_glove_embeddings(glove_file_path, 300)\n",
        "embedding_matrix = create_embedding_matrix(tokenizer.word_index, glove_embeddings, VOCAB_SIZE, 300)\n",
        "\n",
        "# C-LSTM Model for Binary Classification\n",
        "class CLSTMBinaryYelpClassifier(tf.keras.Model):\n",
        "    def __init__(self, config, embedding_matrix):\n",
        "        super(CLSTMBinaryYelpClassifier, self).__init__()\n",
        "        self.max_length = config.max_length\n",
        "        self.num_classes = config.num_classes\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.embedding_size = config.embedding_size\n",
        "        self.filter_sizes = list(map(int, config.filter_sizes.split(\",\")))\n",
        "        self.num_filters = config.num_filters\n",
        "        self.hidden_size = len(self.filter_sizes) * self.num_filters\n",
        "        self.l2_reg_lambda = config.l2_reg_lambda\n",
        "\n",
        "        # Embedding layer initialized with GloVe embeddings\n",
        "        self.embedding = layers.Embedding(input_dim=self.vocab_size,\n",
        "                                          output_dim=self.embedding_size,\n",
        "                                          input_length=self.max_length,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          trainable=True)\n",
        "\n",
        "        # Convolutional layers for different filter sizes\n",
        "        self.conv_layers = [\n",
        "            layers.Conv2D(filters=self.num_filters,\n",
        "                          kernel_size=(filter_size, self.embedding_size),\n",
        "                          activation='relu', padding='valid')\n",
        "            for filter_size in self.filter_sizes\n",
        "        ]\n",
        "\n",
        "        # LSTM layer to capture dependencies\n",
        "        self.lstm = layers.LSTM(self.hidden_size, return_sequences=False)\n",
        "\n",
        "        self.dropout = layers.Dropout(rate=config.keep_prob)\n",
        "\n",
        "        # Fully connected layer for binary classification (2 classes)\n",
        "        self.fc = layers.Dense(self.num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(self.l2_reg_lambda))\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.embedding(inputs)  # [batch_size, max_length, embedding_size]\n",
        "        x = tf.expand_dims(x, -1)   # [batch_size, max_length, embedding_size, 1]\n",
        "\n",
        "        conv_outputs = []\n",
        "        for conv_layer in self.conv_layers:\n",
        "            conv = conv_layer(x)\n",
        "            conv = tf.squeeze(conv, 2)  # Squeeze channels dimension\n",
        "            conv_outputs.append(conv)\n",
        "\n",
        "        # Trimming all conv outputs to the same sequence length\n",
        "        min_length = min([conv.shape[1] for conv in conv_outputs])\n",
        "        conv_outputs = [conv[:, :min_length, :] for conv in conv_outputs]\n",
        "\n",
        "        # Concatenate conv outputs if more than one\n",
        "        if len(conv_outputs) > 1:\n",
        "            rnn_inputs = tf.concat(conv_outputs, -1)\n",
        "        else:\n",
        "            rnn_inputs = conv_outputs[0]\n",
        "\n",
        "        # LSTM layer\n",
        "        rnn_outputs = self.lstm(rnn_inputs)\n",
        "\n",
        "        # Apply dropout\n",
        "        rnn_outputs = self.dropout(rnn_outputs, training=training)\n",
        "\n",
        "        # Output layer (binary classification)\n",
        "        logits = self.fc(rnn_outputs)\n",
        "        return logits\n",
        "\n",
        "# Configuration for the model\n",
        "class Config:\n",
        "    max_length = 300\n",
        "    num_classes = 2  # Binary classification\n",
        "    vocab_size = VOCAB_SIZE\n",
        "    embedding_size = 300  # GloVe embeddings size\n",
        "    filter_sizes = \"3,4,5\"  # Convolution filter sizes\n",
        "    num_filters = 64  # Number of filters for each filter size\n",
        "    l2_reg_lambda = 0.1  # Regularization\n",
        "    keep_prob = 0.5  # Dropout probability\n",
        "\n",
        "# Instantiate config and the model\n",
        "config = Config()\n",
        "model = CLSTMBinaryYelpClassifier(config, embedding_matrix)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az603bpshitD",
        "outputId": "7b61b474-ad82-435a-d67c-79d9889b3aa1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 17ms/step - accuracy: 0.8440 - loss: 0.3785 - val_accuracy: 0.8952 - val_loss: 0.2576\n",
            "Epoch 2/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9034 - loss: 0.2436 - val_accuracy: 0.9011 - val_loss: 0.2483\n",
            "Epoch 3/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 17ms/step - accuracy: 0.9144 - loss: 0.2204 - val_accuracy: 0.9028 - val_loss: 0.2461\n",
            "Epoch 4/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9250 - loss: 0.1985 - val_accuracy: 0.9004 - val_loss: 0.2637\n",
            "Epoch 5/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9340 - loss: 0.1796 - val_accuracy: 0.8995 - val_loss: 0.2583\n",
            "Epoch 6/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9421 - loss: 0.1639 - val_accuracy: 0.8956 - val_loss: 0.2761\n",
            "Epoch 7/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9492 - loss: 0.1483 - val_accuracy: 0.8944 - val_loss: 0.2855\n",
            "Epoch 8/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9557 - loss: 0.1333 - val_accuracy: 0.8931 - val_loss: 0.2919\n",
            "Epoch 9/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9602 - loss: 0.1246 - val_accuracy: 0.8925 - val_loss: 0.2926\n",
            "Epoch 10/10\n",
            "\u001b[1m8125/8125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 17ms/step - accuracy: 0.9638 - loss: 0.1160 - val_accuracy: 0.8876 - val_loss: 0.3190\n",
            "\u001b[1m4063/4063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - accuracy: 0.8889 - loss: 0.3148\n",
            "Test Loss: 0.31902211904525757, Test Accuracy: 0.8876307606697083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "njWo9dtAhpEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BINARY C-LSTM on TREC\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "t17vwlhWmoUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow scikit-learn datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6h6wAoTmny1",
        "outputId": "caf9cc85-3959-4241-d3c4-c6c6e68d847f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.8)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers  # This is the missing import\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the TREC dataset\n",
        "dataset = load_dataset(\"trec\", trust_remote_code=True)\n",
        "\n",
        "# Extract training and test data\n",
        "train_sentences = dataset['train']['text']\n",
        "train_labels = dataset['train']['coarse_label']  # Corrected: 'coarse_label'\n",
        "test_sentences = dataset['test']['text']\n",
        "test_labels = dataset['test']['coarse_label']  # Corrected: 'coarse_label'\n",
        "\n",
        "# Convert labels to binary classification problem\n",
        "# For example, let's group labels into 0-2 -> Class 0, 3-5 -> Class 1 (binary classification)\n",
        "def convert_to_binary_labels(labels):\n",
        "    return [0 if label < 3 else 1 for label in labels]\n",
        "\n",
        "train_binary_labels = convert_to_binary_labels(train_labels)\n",
        "test_binary_labels = convert_to_binary_labels(test_labels)\n",
        "\n",
        "# Tokenization and padding\n",
        "VOCAB_SIZE = 10000\n",
        "MAX_LEN = 100  # Max sequence length for questions\n",
        "\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "# Padding sequences\n",
        "x_train = pad_sequences(train_sequences, maxlen=MAX_LEN)\n",
        "x_test = pad_sequences(test_sequences, maxlen=MAX_LEN)\n",
        "y_train = np.array(train_binary_labels)\n",
        "y_test = np.array(test_binary_labels)\n",
        "\n",
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(glove_file_path, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding_vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = embedding_vector\n",
        "    return embeddings_index\n",
        "\n",
        "def create_embedding_matrix(word_index, glove_embeddings, vocab_size, embedding_dim):\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i < vocab_size:\n",
        "            embedding_vector = glove_embeddings.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "# Load GloVe embeddings\n",
        "glove_file_path = '/content/drive/MyDrive/glove/glove.6B.300d.txt'  # Update this path\n",
        "glove_embeddings = load_glove_embeddings(glove_file_path, 300)\n",
        "\n",
        "# Create embedding matrix for the vocabulary\n",
        "embedding_matrix = create_embedding_matrix(tokenizer.word_index, glove_embeddings, VOCAB_SIZE, 300)\n",
        "\n",
        "# C-LSTM Model for Binary Classification\n",
        "class CLSTMBinaryTRECClassifier(tf.keras.Model):\n",
        "    def __init__(self, config, embedding_matrix):\n",
        "        super(CLSTMBinaryTRECClassifier, self).__init__()\n",
        "        self.max_length = config.max_length\n",
        "        self.num_classes = config.num_classes\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.embedding_size = config.embedding_size\n",
        "        self.filter_sizes = list(map(int, config.filter_sizes.split(\",\")))\n",
        "        self.num_filters = config.num_filters\n",
        "        self.hidden_size = len(self.filter_sizes) * self.num_filters\n",
        "        self.l2_reg_lambda = config.l2_reg_lambda\n",
        "\n",
        "        # Embedding layer initialized with GloVe embeddings\n",
        "        self.embedding = layers.Embedding(input_dim=self.vocab_size,\n",
        "                                          output_dim=self.embedding_size,\n",
        "                                          input_length=self.max_length,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          trainable=True)\n",
        "\n",
        "        # Convolution layers for different filter sizes\n",
        "        self.conv_layers = [\n",
        "            layers.Conv2D(filters=self.num_filters,\n",
        "                          kernel_size=(filter_size, self.embedding_size),\n",
        "                          activation='relu', padding='valid')\n",
        "            for filter_size in self.filter_sizes\n",
        "        ]\n",
        "\n",
        "        # LSTM layer to capture long-term dependencies\n",
        "        self.lstm = layers.LSTM(self.hidden_size, return_sequences=False)\n",
        "\n",
        "        self.dropout = layers.Dropout(rate=config.keep_prob)\n",
        "\n",
        "        # Fully connected layer for binary classification\n",
        "        self.fc = layers.Dense(self.num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(self.l2_reg_lambda))\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.embedding(inputs)  # [batch_size, max_length, embedding_size]\n",
        "        x = tf.expand_dims(x, -1)   # [batch_size, max_length, embedding_size, 1]\n",
        "\n",
        "        conv_outputs = []\n",
        "        for conv_layer in self.conv_layers:\n",
        "            conv = conv_layer(x)\n",
        "            conv = tf.squeeze(conv, 2)  # Squeeze channels dimension\n",
        "            conv_outputs.append(conv)\n",
        "\n",
        "        # Trimming all conv outputs to the same sequence length\n",
        "        min_length = min([conv.shape[1] for conv in conv_outputs])\n",
        "        conv_outputs = [conv[:, :min_length, :] for conv in conv_outputs]\n",
        "\n",
        "        # Concatenate conv outputs if more than one\n",
        "        if len(conv_outputs) > 1:\n",
        "            rnn_inputs = tf.concat(conv_outputs, -1)\n",
        "        else:\n",
        "            rnn_inputs = conv_outputs[0]\n",
        "\n",
        "        # LSTM layer\n",
        "        rnn_outputs = self.lstm(rnn_inputs)\n",
        "\n",
        "        # Apply dropout\n",
        "        rnn_outputs = self.dropout(rnn_outputs, training=training)\n",
        "\n",
        "        # Output layer (binary classification)\n",
        "        logits = self.fc(rnn_outputs)\n",
        "        return logits\n",
        "\n",
        "# Configuration for the model\n",
        "class Config:\n",
        "    max_length = MAX_LEN\n",
        "    num_classes = 2  # Binary classification\n",
        "    vocab_size = VOCAB_SIZE\n",
        "    embedding_size = 300  # GloVe embeddings size\n",
        "    filter_sizes = \"3,4,5\"  # Convolution filter sizes\n",
        "    num_filters = 64  # Number of filters for each filter size\n",
        "    l2_reg_lambda = 0.1  # Regularization\n",
        "    keep_prob = 0.5  # Dropout probability\n",
        "\n",
        "# Instantiate config and the model\n",
        "config = Config()\n",
        "model = CLSTMBinaryTRECClassifier(config, embedding_matrix)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjn1Iryjmnv-",
        "outputId": "7a8b279e-798f-4fd2-c030-7efd630bc12f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.7325 - loss: 0.7947 - val_accuracy: 0.8660 - val_loss: 0.4028\n",
            "Epoch 2/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9205 - loss: 0.2747 - val_accuracy: 0.9280 - val_loss: 0.2676\n",
            "Epoch 3/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9634 - loss: 0.1372 - val_accuracy: 0.9220 - val_loss: 0.2656\n",
            "Epoch 4/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9848 - loss: 0.0722 - val_accuracy: 0.9360 - val_loss: 0.2631\n",
            "Epoch 5/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9897 - loss: 0.0579 - val_accuracy: 0.9200 - val_loss: 0.3197\n",
            "Epoch 6/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9931 - loss: 0.0454 - val_accuracy: 0.9360 - val_loss: 0.2897\n",
            "Epoch 7/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9962 - loss: 0.0324 - val_accuracy: 0.9360 - val_loss: 0.3049\n",
            "Epoch 8/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9984 - loss: 0.0274 - val_accuracy: 0.9360 - val_loss: 0.3002\n",
            "Epoch 9/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9989 - loss: 0.0233 - val_accuracy: 0.9380 - val_loss: 0.3184\n",
            "Epoch 10/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9996 - loss: 0.0193 - val_accuracy: 0.9420 - val_loss: 0.3049\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9410 - loss: 0.3039\n",
            "Test Loss: 0.30485260486602783, Test Accuracy: 0.9419999718666077\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yHlD71rkmntx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINE-GRAINED C-LSTM on TREC\n",
        ""
      ],
      "metadata": {
        "id": "yAfZTgIzqwul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the TREC dataset\n",
        "dataset = load_dataset(\"trec\")\n",
        "\n",
        "# Extract training and test data\n",
        "train_sentences = dataset['train']['text']\n",
        "train_labels = dataset['train']['fine_label']  # Fine labels: 50 categories\n",
        "test_sentences = dataset['test']['text']\n",
        "test_labels = dataset['test']['fine_label']  # Fine labels: 50 categories\n",
        "\n",
        "# Tokenization and padding\n",
        "VOCAB_SIZE = 10000\n",
        "MAX_LEN = 100  # Max sequence length for questions\n",
        "\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "# Padding sequences\n",
        "x_train = pad_sequences(train_sequences, maxlen=MAX_LEN)\n",
        "x_test = pad_sequences(test_sequences, maxlen=MAX_LEN)\n",
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(glove_file_path, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding_vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = embedding_vector\n",
        "    return embeddings_index\n",
        "\n",
        "def create_embedding_matrix(word_index, glove_embeddings, vocab_size, embedding_dim):\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i < vocab_size:\n",
        "            embedding_vector = glove_embeddings.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "# Load GloVe embeddings\n",
        "glove_file_path = '/content/drive/MyDrive/glove/glove.6B.300d.txt'  # Update this path\n",
        "glove_embeddings = load_glove_embeddings(glove_file_path, 300)\n",
        "\n",
        "# Create embedding matrix for the vocabulary\n",
        "embedding_matrix = create_embedding_matrix(tokenizer.word_index, glove_embeddings, VOCAB_SIZE, 300)\n",
        "\n",
        "# C-LSTM Model for Fine-Grained Classification\n",
        "class CLSTMFineGrainedTRECClassifier(tf.keras.Model):\n",
        "    def __init__(self, config, embedding_matrix):\n",
        "        super(CLSTMFineGrainedTRECClassifier, self).__init__()\n",
        "        self.max_length = config.max_length\n",
        "        self.num_classes = config.num_classes  # Now it's fine-grained classification\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.embedding_size = config.embedding_size\n",
        "        self.filter_sizes = list(map(int, config.filter_sizes.split(\",\")))\n",
        "        self.num_filters = config.num_filters\n",
        "        self.hidden_size = len(self.filter_sizes) * self.num_filters\n",
        "        self.l2_reg_lambda = config.l2_reg_lambda\n",
        "\n",
        "        # Embedding layer initialized with GloVe embeddings\n",
        "        self.embedding = layers.Embedding(input_dim=self.vocab_size,\n",
        "                                          output_dim=self.embedding_size,\n",
        "                                          input_length=self.max_length,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          trainable=True)\n",
        "\n",
        "        # Convolution layers for different filter sizes\n",
        "        self.conv_layers = [\n",
        "            layers.Conv2D(filters=self.num_filters,\n",
        "                          kernel_size=(filter_size, self.embedding_size),\n",
        "                          activation='relu', padding='valid')\n",
        "            for filter_size in self.filter_sizes\n",
        "        ]\n",
        "\n",
        "        # LSTM layer to capture long-term dependencies\n",
        "        self.lstm = layers.LSTM(self.hidden_size, return_sequences=False)\n",
        "\n",
        "        self.dropout = layers.Dropout(rate=config.keep_prob)\n",
        "\n",
        "        # Fully connected layer for fine-grained classification (50 classes)\n",
        "        self.fc = layers.Dense(self.num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(self.l2_reg_lambda))\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.embedding(inputs)  # [batch_size, max_length, embedding_size]\n",
        "        x = tf.expand_dims(x, -1)   # [batch_size, max_length, embedding_size, 1]\n",
        "\n",
        "        conv_outputs = []\n",
        "        for conv_layer in self.conv_layers:\n",
        "            conv = conv_layer(x)\n",
        "            conv = tf.squeeze(conv, 2)  # Squeeze channels dimension\n",
        "            conv_outputs.append(conv)\n",
        "\n",
        "        # Trimming all conv outputs to the same sequence length\n",
        "        min_length = min([conv.shape[1] for conv in conv_outputs])\n",
        "        conv_outputs = [conv[:, :min_length, :] for conv in conv_outputs]\n",
        "\n",
        "        # Concatenate conv outputs if more than one\n",
        "        if len(conv_outputs) > 1:\n",
        "            rnn_inputs = tf.concat(conv_outputs, -1)\n",
        "        else:\n",
        "            rnn_inputs = conv_outputs[0]\n",
        "\n",
        "        # LSTM layer\n",
        "        rnn_outputs = self.lstm(rnn_inputs)\n",
        "\n",
        "        # Apply dropout\n",
        "        rnn_outputs = self.dropout(rnn_outputs, training=training)\n",
        "\n",
        "        # Output layer (fine-grained classification with 50 classes)\n",
        "        logits = self.fc(rnn_outputs)\n",
        "        return logits\n",
        "\n",
        "# Configuration for the model\n",
        "class Config:\n",
        "    max_length = MAX_LEN\n",
        "    num_classes = 50  # Fine-grained classification (50 classes)\n",
        "    vocab_size = VOCAB_SIZE\n",
        "    embedding_size = 300  # GloVe embeddings size\n",
        "    filter_sizes = \"3,4,5\"  # Convolution filter sizes\n",
        "    num_filters = 64  # Number of filters for each filter size\n",
        "    l2_reg_lambda = 0.1  # Regularization\n",
        "    keep_prob = 0.5  # Dropout probability\n",
        "\n",
        "# Instantiate config and the model\n",
        "config = Config()\n",
        "model = CLSTMFineGrainedTRECClassifier(config, embedding_matrix)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqVh4_XumnqW",
        "outputId": "c93f47d5-a6a8-4420-87c0-f973aea9b711"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.2365 - loss: 8.7466 - val_accuracy: 0.5220 - val_loss: 3.9876\n",
            "Epoch 2/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4983 - loss: 3.1919 - val_accuracy: 0.5820 - val_loss: 2.6429\n",
            "Epoch 3/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6129 - loss: 2.0846 - val_accuracy: 0.5980 - val_loss: 2.3345\n",
            "Epoch 4/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6986 - loss: 1.7205 - val_accuracy: 0.6220 - val_loss: 2.2469\n",
            "Epoch 5/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7484 - loss: 1.5472 - val_accuracy: 0.6440 - val_loss: 2.1575\n",
            "Epoch 6/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7945 - loss: 1.3928 - val_accuracy: 0.6780 - val_loss: 2.1095\n",
            "Epoch 7/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8357 - loss: 1.2688 - val_accuracy: 0.6900 - val_loss: 2.0495\n",
            "Epoch 8/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8592 - loss: 1.1862 - val_accuracy: 0.7140 - val_loss: 2.0260\n",
            "Epoch 9/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8924 - loss: 1.0968 - val_accuracy: 0.7140 - val_loss: 2.0049\n",
            "Epoch 10/10\n",
            "\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9050 - loss: 1.0570 - val_accuracy: 0.7300 - val_loss: 1.9344\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7354 - loss: 1.9553 \n",
            "Test Loss: 1.9344199895858765, Test Accuracy: 0.7300000190734863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8H2AtprPmnnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5NPn9dafmnlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gvdo48mYmnid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BINARY CLASSIFICATION C-LSTM on 20 NEWSGROUP\n",
        ""
      ],
      "metadata": {
        "id": "z1zFv7eiq8pE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow scikit-learn datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgVKgbcYiQZf",
        "outputId": "cc27f768-c62b-404e-ede4-614b2727dc26"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.8)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the 20 Newsgroups dataset\n",
        "newsgroups = fetch_20newsgroups(subset='all', categories=None, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Texts and labels\n",
        "texts = newsgroups.data\n",
        "labels = newsgroups.target\n",
        "\n",
        "# Define a binary classification scenario (e.g., 'sci.space' vs 'rec.sport.baseball')\n",
        "categories = ['sci.space', 'rec.sport.baseball']\n",
        "newsgroups_binary = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Binary texts and labels\n",
        "texts_binary = newsgroups_binary.data\n",
        "labels_binary = newsgroups_binary.target  # 0 for 'rec.sport.baseball', 1 for 'sci.space'\n",
        "\n",
        "# Tokenization and padding\n",
        "VOCAB_SIZE = 10000\n",
        "MAX_LEN = 300  # Maximum sequence length\n",
        "\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(texts_binary)\n",
        "sequences = tokenizer.texts_to_sequences(texts_binary)\n",
        "x_data = pad_sequences(sequences, maxlen=MAX_LEN)\n",
        "y_data = np.array(labels_binary)\n",
        "\n",
        "# Split data into training and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(glove_file_path, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding_vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = embedding_vector\n",
        "    return embeddings_index\n",
        "\n",
        "# Create embedding matrix\n",
        "def create_embedding_matrix(word_index, glove_embeddings, vocab_size, embedding_dim):\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i < vocab_size:\n",
        "            embedding_vector = glove_embeddings.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "# Load GloVe embeddings\n",
        "glove_file_path = '/content/drive/MyDrive/glove/glove.6B.300d.txt'  # Update with your GloVe path\n",
        "glove_embeddings = load_glove_embeddings(glove_file_path, 300)\n",
        "embedding_matrix = create_embedding_matrix(tokenizer.word_index, glove_embeddings, VOCAB_SIZE, 300)\n",
        "\n",
        "# C-LSTM Model for Binary Classification\n",
        "class CLSTMBinaryNewsgroupsClassifier(tf.keras.Model):\n",
        "    def __init__(self, config, embedding_matrix):\n",
        "        super(CLSTMBinaryNewsgroupsClassifier, self).__init__()\n",
        "        self.max_length = config.max_length\n",
        "        self.num_classes = config.num_classes\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.embedding_size = config.embedding_size\n",
        "        self.filter_sizes = list(map(int, config.filter_sizes.split(\",\")))\n",
        "        self.num_filters = config.num_filters\n",
        "        self.hidden_size = len(self.filter_sizes) * self.num_filters\n",
        "        self.l2_reg_lambda = config.l2_reg_lambda\n",
        "\n",
        "        # Embedding layer initialized with GloVe embeddings\n",
        "        self.embedding = layers.Embedding(input_dim=self.vocab_size,\n",
        "                                          output_dim=self.embedding_size,\n",
        "                                          input_length=self.max_length,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          trainable=True)\n",
        "\n",
        "        # Convolutional layers for different filter sizes\n",
        "        self.conv_layers = [\n",
        "            layers.Conv2D(filters=self.num_filters,\n",
        "                          kernel_size=(filter_size, self.embedding_size),\n",
        "                          activation='relu', padding='valid')\n",
        "            for filter_size in self.filter_sizes\n",
        "        ]\n",
        "\n",
        "        # LSTM layer to capture dependencies\n",
        "        self.lstm = layers.LSTM(self.hidden_size, return_sequences=False)\n",
        "\n",
        "        self.dropout = layers.Dropout(rate=config.keep_prob)\n",
        "\n",
        "        # Fully connected layer for binary classification\n",
        "        self.fc = layers.Dense(self.num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(self.l2_reg_lambda))\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.embedding(inputs)  # [batch_size, max_length, embedding_size]\n",
        "        x = tf.expand_dims(x, -1)   # [batch_size, max_length, embedding_size, 1]\n",
        "\n",
        "        conv_outputs = []\n",
        "        for conv_layer in self.conv_layers:\n",
        "            conv = conv_layer(x)\n",
        "            conv = tf.squeeze(conv, 2)  # Squeeze channels dimension\n",
        "            conv_outputs.append(conv)\n",
        "\n",
        "        # Trimming all conv outputs to the same sequence length\n",
        "        min_length = min([conv.shape[1] for conv in conv_outputs])\n",
        "        conv_outputs = [conv[:, :min_length, :] for conv in conv_outputs]\n",
        "\n",
        "        # Concatenate conv outputs if more than one\n",
        "        if len(conv_outputs) > 1:\n",
        "            rnn_inputs = tf.concat(conv_outputs, -1)\n",
        "        else:\n",
        "            rnn_inputs = conv_outputs[0]\n",
        "\n",
        "        # LSTM layer\n",
        "        rnn_outputs = self.lstm(rnn_inputs)\n",
        "\n",
        "        # Apply dropout\n",
        "        rnn_outputs = self.dropout(rnn_outputs, training=training)\n",
        "\n",
        "        # Output layer (binary classification)\n",
        "        logits = self.fc(rnn_outputs)\n",
        "        return logits\n",
        "\n",
        "# Configuration for the model\n",
        "class Config:\n",
        "    max_length = 300\n",
        "    num_classes = 2  # Binary classification\n",
        "    vocab_size = VOCAB_SIZE\n",
        "    embedding_size = 300  # GloVe embeddings size\n",
        "    filter_sizes = \"3,4,5\"  # Convolution filter sizes\n",
        "    num_filters = 64  # Number of filters for each filter size\n",
        "    l2_reg_lambda = 0.1  # Regularization\n",
        "    keep_prob = 0.5  # Dropout probability\n",
        "\n",
        "# Instantiate config and the model\n",
        "config = Config()\n",
        "model = CLSTMBinaryNewsgroupsClassifier(config, embedding_matrix)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LuCsAjak13U",
        "outputId": "42321955-c134-47a5-ec78-4c71f549560d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 432ms/step - accuracy: 0.6966 - loss: 0.9041 - val_accuracy: 0.8917 - val_loss: 0.5623\n",
            "Epoch 2/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9016 - loss: 0.5027 - val_accuracy: 0.9169 - val_loss: 0.3685\n",
            "Epoch 3/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9306 - loss: 0.3255 - val_accuracy: 0.9169 - val_loss: 0.2832\n",
            "Epoch 4/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9619 - loss: 0.2000 - val_accuracy: 0.9295 - val_loss: 0.2148\n",
            "Epoch 5/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9716 - loss: 0.1384 - val_accuracy: 0.9320 - val_loss: 0.2062\n",
            "Epoch 6/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9528 - loss: 0.1857 - val_accuracy: 0.9370 - val_loss: 0.1656\n",
            "Epoch 7/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9704 - loss: 0.1121 - val_accuracy: 0.9471 - val_loss: 0.1490\n",
            "Epoch 8/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9787 - loss: 0.0921 - val_accuracy: 0.9395 - val_loss: 0.1449\n",
            "Epoch 9/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9848 - loss: 0.0706 - val_accuracy: 0.9471 - val_loss: 0.1439\n",
            "Epoch 10/10\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9844 - loss: 0.0619 - val_accuracy: 0.9395 - val_loss: 0.1493\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9494 - loss: 0.1064\n",
            "Test Loss: 0.14925351738929749, Test Accuracy: 0.9395465850830078\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rY6EiWtr3P0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-grained on 20Newsgroup"
      ],
      "metadata": {
        "id": "2tKhoC6d649x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Load the 20 Newsgroups dataset with all categories\n",
        "newsgroups = fetch_20newsgroups(subset='all', categories=None, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Texts and labels\n",
        "texts = newsgroups.data\n",
        "labels = newsgroups.target\n",
        "\n",
        "# Tokenization and padding\n",
        "VOCAB_SIZE = 10000\n",
        "MAX_LEN = 300  # Maximum sequence length\n",
        "\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "x_data = pad_sequences(sequences, maxlen=MAX_LEN)\n",
        "\n",
        "# Encode labels into 0-19 for 20 newsgroups categories\n",
        "y_data = np.array(labels)\n",
        "\n",
        "# Split data into training and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(glove_file_path, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding_vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = embedding_vector\n",
        "    return embeddings_index\n",
        "\n",
        "# Create embedding matrix\n",
        "def create_embedding_matrix(word_index, glove_embeddings, vocab_size, embedding_dim):\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i < vocab_size:\n",
        "            embedding_vector = glove_embeddings.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "# Load GloVe embeddings\n",
        "glove_file_path = '/content/drive/MyDrive/glove/glove.6B.300d.txt'  # Update with your GloVe path\n",
        "glove_embeddings = load_glove_embeddings(glove_file_path, 300)\n",
        "embedding_matrix = create_embedding_matrix(tokenizer.word_index, glove_embeddings, VOCAB_SIZE, 300)\n",
        "\n",
        "# C-LSTM Model for Fine-Grained Classification (20 categories)\n",
        "class CLSTMFineGrainedNewsgroupsClassifier(tf.keras.Model):\n",
        "    def __init__(self, config, embedding_matrix):\n",
        "        super(CLSTMFineGrainedNewsgroupsClassifier, self).__init__()\n",
        "        self.max_length = config.max_length\n",
        "        self.num_classes = config.num_classes\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.embedding_size = config.embedding_size\n",
        "        self.filter_sizes = list(map(int, config.filter_sizes.split(\",\")))\n",
        "        self.num_filters = config.num_filters\n",
        "        self.hidden_size = len(self.filter_sizes) * self.num_filters\n",
        "        self.l2_reg_lambda = config.l2_reg_lambda\n",
        "\n",
        "        # Embedding layer initialized with GloVe embeddings\n",
        "        self.embedding = layers.Embedding(input_dim=self.vocab_size,\n",
        "                                          output_dim=self.embedding_size,\n",
        "                                          input_length=self.max_length,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          trainable=True)\n",
        "\n",
        "        # Convolutional layers for different filter sizes\n",
        "        self.conv_layers = [\n",
        "            layers.Conv2D(filters=self.num_filters,\n",
        "                          kernel_size=(filter_size, self.embedding_size),\n",
        "                          activation='relu', padding='valid')\n",
        "            for filter_size in self.filter_sizes\n",
        "        ]\n",
        "\n",
        "        # LSTM layer to capture dependencies\n",
        "        self.lstm = layers.LSTM(self.hidden_size, return_sequences=False)\n",
        "\n",
        "        self.dropout = layers.Dropout(rate=config.keep_prob)\n",
        "\n",
        "        # Fully connected layer for fine-grained classification (20 categories)\n",
        "        self.fc = layers.Dense(self.num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(self.l2_reg_lambda))\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.embedding(inputs)  # [batch_size, max_length, embedding_size]\n",
        "        x = tf.expand_dims(x, -1)   # [batch_size, max_length, embedding_size, 1]\n",
        "\n",
        "        conv_outputs = []\n",
        "        for conv_layer in self.conv_layers:\n",
        "            conv = conv_layer(x)\n",
        "            conv = tf.squeeze(conv, 2)  # Squeeze channels dimension\n",
        "            conv_outputs.append(conv)\n",
        "\n",
        "        # Trimming all conv outputs to the same sequence length\n",
        "        min_length = min([conv.shape[1] for conv in conv_outputs])\n",
        "        conv_outputs = [conv[:, :min_length, :] for conv in conv_outputs]\n",
        "\n",
        "        # Concatenate conv outputs if more than one\n",
        "        if len(conv_outputs) > 1:\n",
        "            rnn_inputs = tf.concat(conv_outputs, -1)\n",
        "        else:\n",
        "            rnn_inputs = conv_outputs[0]\n",
        "\n",
        "        # LSTM layer\n",
        "        rnn_outputs = self.lstm(rnn_inputs)\n",
        "\n",
        "        # Apply dropout\n",
        "        rnn_outputs = self.dropout(rnn_outputs, training=training)\n",
        "\n",
        "        # Output layer (fine-grained classification)\n",
        "        logits = self.fc(rnn_outputs)\n",
        "        return logits\n",
        "\n",
        "# Configuration for the model\n",
        "class Config:\n",
        "    max_length = 300\n",
        "    num_classes = 20  # Fine-grained classification: 20 categories\n",
        "    vocab_size = VOCAB_SIZE\n",
        "    embedding_size = 300  # GloVe embeddings size\n",
        "    filter_sizes = \"3,4,5\"  # Convolution filter sizes\n",
        "    num_filters = 64  # Number of filters for each filter size\n",
        "    l2_reg_lambda = 0.1  # Regularization\n",
        "    keep_prob = 0.5  # Dropout probability\n",
        "\n",
        "# Instantiate config and the model\n",
        "config = Config()\n",
        "model = CLSTMFineGrainedNewsgroupsClassifier(config, embedding_matrix)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dmrVXmf65Xv",
        "outputId": "d8dcc66a-062b-400a-9575-4689219145b0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 51ms/step - accuracy: 0.1420 - loss: 4.3812 - val_accuracy: 0.3170 - val_loss: 2.2588\n",
            "Epoch 2/10\n",
            "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.3324 - loss: 2.1876 - val_accuracy: 0.3785 - val_loss: 2.0136\n",
            "Epoch 3/10\n",
            "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.4528 - loss: 1.8125 - val_accuracy: 0.4838 - val_loss: 1.7625\n",
            "Epoch 4/10\n",
            "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.5373 - loss: 1.6040 - val_accuracy: 0.4987 - val_loss: 1.6743\n",
            "Epoch 5/10\n",
            "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.5744 - loss: 1.4780 - val_accuracy: 0.5353 - val_loss: 1.6419\n",
            "Epoch 6/10\n",
            "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.6263 - loss: 1.3773 - val_accuracy: 0.5798 - val_loss: 1.6189\n",
            "Epoch 7/10\n",
            "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.6799 - loss: 1.2944 - val_accuracy: 0.6050 - val_loss: 1.5849\n",
            "Epoch 8/10\n",
            "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7460 - loss: 1.1885 - val_accuracy: 0.6241 - val_loss: 1.5474\n",
            "Epoch 9/10\n",
            "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7868 - loss: 1.1292 - val_accuracy: 0.6507 - val_loss: 1.5252\n",
            "Epoch 10/10\n",
            "\u001b[1m236/236\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.8132 - loss: 1.0708 - val_accuracy: 0.6353 - val_loss: 1.5665\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6283 - loss: 1.6000\n",
            "Test Loss: 1.5664937496185303, Test Accuracy: 0.6352785229682922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Nin2jmX6-S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8diLLeH-9P18",
        "outputId": "96bc7923-9eb2-4fa5-bd81-c4526bc1defe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.8)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary classification C-LSTM on AG News Dataset"
      ],
      "metadata": {
        "id": "dilwUxem7VTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Load AG News Dataset from Hugging Face\n",
        "dataset = load_dataset(\"ag_news\")\n",
        "\n",
        "# Select only two categories for binary classification (e.g., World and Sports)\n",
        "def filter_categories(dataset, categories):\n",
        "    filtered_texts = []\n",
        "    filtered_labels = []\n",
        "    for i in range(len(dataset['text'])):\n",
        "        if dataset['label'][i] in categories:\n",
        "            filtered_texts.append(dataset['text'][i])\n",
        "            filtered_labels.append(categories.index(dataset['label'][i]))\n",
        "    return filtered_texts, filtered_labels\n",
        "\n",
        "# Use label 0 (World) and label 1 (Sports) for binary classification\n",
        "categories = [0, 1]  # World and Sports categories\n",
        "train_texts, train_labels = filter_categories(dataset['train'], categories)\n",
        "test_texts, test_labels = filter_categories(dataset['test'], categories)\n",
        "\n",
        "# Tokenization and padding\n",
        "VOCAB_SIZE = 10000\n",
        "MAX_LEN = 300  # Max sequence length\n",
        "\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "# Pad the sequences\n",
        "x_train = pad_sequences(train_sequences, maxlen=MAX_LEN)\n",
        "x_test = pad_sequences(test_sequences, maxlen=MAX_LEN)\n",
        "\n",
        "# Convert labels to numpy arrays\n",
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(glove_file_path, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding_vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = embedding_vector\n",
        "    return embeddings_index\n",
        "\n",
        "# Create embedding matrix\n",
        "def create_embedding_matrix(word_index, glove_embeddings, vocab_size, embedding_dim):\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        if i < vocab_size:\n",
        "            embedding_vector = glove_embeddings.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n",
        "\n",
        "# Load pre-trained GloVe embeddings (adjust the path)\n",
        "glove_file_path = '/content/drive/MyDrive/glove/glove.6B.300d.txt'\n",
        "glove_embeddings = load_glove_embeddings(glove_file_path, 300)\n",
        "embedding_matrix = create_embedding_matrix(tokenizer.word_index, glove_embeddings, VOCAB_SIZE, 300)\n",
        "\n",
        "# C-LSTM Model for Binary Classification\n",
        "class CLSTMBinaryAGNewsClassifier(tf.keras.Model):\n",
        "    def __init__(self, config, embedding_matrix):\n",
        "        super(CLSTMBinaryAGNewsClassifier, self).__init__()\n",
        "        self.max_length = config.max_length\n",
        "        self.num_classes = config.num_classes\n",
        "        self.vocab_size = config.vocab_size\n",
        "        self.embedding_size = config.embedding_size\n",
        "        self.filter_sizes = list(map(int, config.filter_sizes.split(\",\")))\n",
        "        self.num_filters = config.num_filters\n",
        "        self.hidden_size = len(self.filter_sizes) * self.num_filters\n",
        "        self.l2_reg_lambda = config.l2_reg_lambda\n",
        "\n",
        "        # Embedding layer initialized with GloVe embeddings\n",
        "        self.embedding = layers.Embedding(input_dim=self.vocab_size,\n",
        "                                          output_dim=self.embedding_size,\n",
        "                                          input_length=self.max_length,\n",
        "                                          weights=[embedding_matrix],\n",
        "                                          trainable=True)\n",
        "\n",
        "        # Convolutional layers for different filter sizes\n",
        "        self.conv_layers = [\n",
        "            layers.Conv2D(filters=self.num_filters,\n",
        "                          kernel_size=(filter_size, self.embedding_size),\n",
        "                          activation='relu', padding='valid')\n",
        "            for filter_size in self.filter_sizes\n",
        "        ]\n",
        "\n",
        "        # LSTM layer to capture dependencies\n",
        "        self.lstm = layers.LSTM(self.hidden_size, return_sequences=False)\n",
        "\n",
        "        self.dropout = layers.Dropout(rate=config.keep_prob)\n",
        "\n",
        "        # Fully connected layer for binary classification\n",
        "        self.fc = layers.Dense(self.num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.L2(self.l2_reg_lambda))\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        x = self.embedding(inputs)  # [batch_size, max_length, embedding_size]\n",
        "        x = tf.expand_dims(x, -1)   # [batch_size, max_length, embedding_size, 1]\n",
        "\n",
        "        conv_outputs = []\n",
        "        for conv_layer in self.conv_layers:\n",
        "            conv = conv_layer(x)\n",
        "            conv = tf.squeeze(conv, 2)  # Squeeze channels dimension\n",
        "            conv_outputs.append(conv)\n",
        "\n",
        "        # Trimming all conv outputs to the same sequence length\n",
        "        min_length = min([conv.shape[1] for conv in conv_outputs])\n",
        "        conv_outputs = [conv[:, :min_length, :] for conv in conv_outputs]\n",
        "\n",
        "        # Concatenate conv outputs if more than one\n",
        "        if len(conv_outputs) > 1:\n",
        "            rnn_inputs = tf.concat(conv_outputs, -1)\n",
        "        else:\n",
        "            rnn_inputs = conv_outputs[0]\n",
        "\n",
        "        # LSTM layer\n",
        "        rnn_outputs = self.lstm(rnn_inputs)\n",
        "\n",
        "        # Apply dropout\n",
        "        rnn_outputs = self.dropout(rnn_outputs, training=training)\n",
        "\n",
        "        # Output layer (binary classification)\n",
        "        logits = self.fc(rnn_outputs)\n",
        "        return logits\n",
        "\n",
        "# Configuration for the model\n",
        "class Config:\n",
        "    max_length = MAX_LEN\n",
        "    num_classes = 2  # Binary classification\n",
        "    vocab_size = VOCAB_SIZE\n",
        "    embedding_size = 300  # GloVe embeddings size\n",
        "    filter_sizes = \"3,4,5\"  # Convolution filter sizes\n",
        "    num_filters = 64  # Number of filters for each filter size\n",
        "    l2_reg_lambda = 0.1  # Regularization\n",
        "    keep_prob = 0.5  # Dropout probability\n",
        "\n",
        "# Instantiate config and the model\n",
        "config = Config()\n",
        "model = CLSTMBinaryAGNewsClassifier(config, embedding_matrix)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "1vw1T1Mx7U60",
        "outputId": "e79a2cc2-237b-4b0c-e28f-232c0c280cc9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-322652f045f9>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Use label 0 (World) and label 1 (Sports) for binary classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# World and Sports categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mtest_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-322652f045f9>\u001b[0m in \u001b[0;36mfilter_categories\u001b[0;34m(dataset, categories)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfiltered_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mfiltered_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mfiltered_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2740\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: F811\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2741\u001b[0m         \u001b[0;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2742\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2744\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m         formatted_output = format_table(\n\u001b[0m\u001b[1;32m   2728\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_features_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mextract_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pylist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ekPCboYY7ydr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}